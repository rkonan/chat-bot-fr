### Question
Quels traitements d'images ont √©t√© appliqu√©s ?

**Top‚ÄëK**: 8

### Top K chunks (rerank cos_sim)
- **#1** | score=0.8157 | id=`5cfd843b-793e-410e-8320-f43342316a90` | len=1630
  
> Autres ‚óè Incompatibilit√©s techniques : Probl√®mes de compatibilit√© entre TensorFlow 2.19 et certains outils d'interpr√©tation (SHAP DeepExplainer, GradCam) ‚óè Migration entre frameworks : Passage de FastAI vers TensorFlow pour faciliter l'int√©gration Firebase, n√©cessitant la r√©-impl√©mentation de certains mod√®les Bilan Contribution principale dans l'atteinte des objectifs Notre con‚Ä¶

- **#2** | score=0.8146 | id=`a4f92528-5418-45a9-a840-5217bb405eec` | len=740
  
> Dans le dataframe des images de bonnes qualit√©s, il y a 79 599 images, dont les trois premi√®res esp√®ces repr√©sentent + 45% du total.  Distribution des esp√®ces dans le dataframe ‚Äúlow quality‚Äù      Il y a 47 069 images, on peut remarquer que l‚Äôensemble des images des esp√®ces cassave, riz, et sucre de canne ne sont pr√©sentes que sur le dataframe de mauvaise qualit√©.  Mesure d‚Äôam√©l‚Ä¶

- **#3** | score=0.8370 | id=`e1b43b2b-1b35-4ba6-ac74-4c6875bd8190` | len=1531
  
> que les images sont devenues plus nettes et moins floues apr√®s avoir subi les ajustements sur la nettet√©.  Analyse du contraste et de la luminosit√© avant et apr√®s retraitement   Les bo√Ætes √† moustaches montrent que le retraitement a am√©lior√© la qualit√© des images en r√©duisant les valeurs aberrantes. Pour le contraste, la m√©diane est rest√©e stable, mais les valeurs tr√®s faibles ‚Ä¶

- **#4** | score=0.8308 | id=`ad89cb8f-62e5-47a3-bba7-38b847fff5c3` | len=1787
  
> A partir du dataframe initial, on parcourt l‚Äôensemble des images gr√¢ce au FilePath pour appliquer nos crit√®res de qualit√© et cr√©er un dataframe (df_high_quality) r√©unissant uniquement les images qui passent le test.   Ceux ne passant pas les crit√®res de qualit√© vont √™tre int√©gr√© √† un dataframe diff√©rent (df_low_quality) pour √™tre trait√©.  Transformations des donn√©es  Traitement‚Ä¶

- **#5** | score=0.8215 | id=`d35af72f-6bf4-4991-911f-528c81941bf0` | len=591
  
> Elle sera ensuite retrait√©e (format JPEG, RGB, redimensionnement et √©ventuellement retraitement du niveau de flou afin de faciliter le diagnostic). Ce premier algorithme de classification, entra√Æn√© sur la base totale des images d√©crite en page 14 et de m√©ta-donn√©es pouvant y √™tre rattach√©es aura √©t√© test√© sur une base constitu√©e de 20% des images concern√©es avec un objectif d‚Äôa‚Ä¶

- **#6** | score=0.8136 | id=`5973f1ca-7fd5-4f81-99b3-3d0d7087f3bf` | len=733
  
> Cette difficult√© refl√®te un d√©fi majeur en reconnaissance d'images agricoles : distinguer les sympt√¥mes subtils de maladies sur des images prises dans des conditions naturelles variables, avec des arri√®re-plans complexes et des variations d'√©clairage. Difficult√©s d√©taill√©es par cat√©gorie Pr√©visionnel ‚Ä¢ Temps de pr√©processing sous-estim√© : Le nettoyage et l'homog√©n√©isation des m‚Ä¶

- **#7** | score=0.8194 | id=`8d9aba35-9f7c-4499-ab1b-36eb07c8a3bc` | len=1956
  
> ‚óè Augmentation cibl√©e : Techniques d'augmentation sp√©cialis√©es par type de maladie (GANs, style transfer) ‚óè Donn√©es multi-modales : Int√©gration d'informations contextuelles (g√©olocalisation, saison, ‚Ä¶) Optimisations architecturales ‚óè Mod√®les hybrides : Combinaison CNN-RNN avec r√©seaux Liquid Time-Constant pour traitement temporel ‚óè Attention mechanisms : Int√©gration de m√©canism‚Ä¶

- **#8** | score=0.8162 | id=`06e8e6f5-fb8d-440e-bde8-7fa6d3d96e7b` | len=1065
  
> ‚Ä¢ Optimisation pour le d√©ploiement mobile : Apprentissage des techniques de compression et quantification de mod√®les pour l'usage sur smartphone Pertinence ‚óè Choix architecturaux : N√©cessit√© de r√©viser l'approche initiale face aux performances insuffisantes sur certaines classes, menant √† l'exploration de mod√®les alternatifs (SwinTransformer) ou l‚Äôutilisation de certaines image‚Ä¶


---
### Contexte concat√©n√© (troncature √©ventuelle)

Autres ‚óè Incompatibilit√©s techniques : Probl√®mes de compatibilit√© entre TensorFlow 2.19 et certains outils d'interpr√©tation (SHAP DeepExplainer, GradCam) ‚óè Migration entre frameworks : Passage de FastAI vers TensorFlow pour faciliter l'int√©gration Firebase, n√©cessitant la r√©-impl√©mentation de certains mod√®les Bilan Contribution principale dans l'atteinte des objectifs Notre contribution principale r√©side dans le d√©veloppement d'une pipeline compl√®te de traitement et de classification d'images de

Dans le dataframe des images de bonnes qualit√©s, il y a 79 599 images, dont les trois premi√®res esp√®ces repr√©sentent + 45% du total.  Distribution des esp√®ces dans le dataframe ‚Äúlow quality‚Äù  
   Il y a 47 069 images, on peut remarquer que l‚Äôensemble des images des esp√®ces cassave, riz, et sucre de canne ne sont pr√©sentes que sur le dataframe de mauvaise qualit√©.  Mesure d‚Äôam√©lioration de la qualit√© des images  Distribution du flou avant/apr√®s retraitements 
 D'apr√®s la visualisation, la densit√©

que les images sont devenues plus nettes et moins floues apr√®s avoir subi les ajustements sur la nettet√©.  Analyse du contraste et de la luminosit√© avant et apr√®s retraitement 
 Les bo√Ætes √† moustaches montrent que le retraitement a am√©lior√© la qualit√© des images en r√©duisant les valeurs aberrantes. Pour le contraste, la m√©diane est rest√©e stable, mais les valeurs tr√®s faibles de contraste ont √©t√© corrig√©es, et la gamme des valeurs s'est √©largie. De m√™me, pour la luminosit√©, la m√©diane est incha

A partir du dataframe initial, on parcourt l‚Äôensemble des images gr√¢ce au FilePath pour appliquer nos crit√®res de qualit√© et cr√©er un dataframe (df_high_quality) r√©unissant uniquement les images qui passent le test.   Ceux ne passant pas les crit√®res de qualit√© vont √™tre int√©gr√© √† un dataframe diff√©rent (df_low_quality) pour √™tre trait√©.  Transformations des donn√©es  Traitement des images Plusieurs traitements sont appliqu√©s aux images dans le but d‚Äôam√©liorer leur qualit√©. Les traitements inclue

Elle sera ensuite retrait√©e (format JPEG, RGB, redimensionnement et √©ventuellement retraitement du niveau de flou afin de faciliter le diagnostic). Ce premier algorithme de classification, entra√Æn√© sur la base totale des images d√©crite en page 14 et de m√©ta-donn√©es pouvant y √™tre rattach√©es aura √©t√© test√© sur une base constitu√©e de 20% des images concern√©es avec un objectif d‚Äôaccuracy de 95%. La base totale des images aura √©t√© probablement corrig√©e afin de minimiser les d√©s√©quilibres entre class

Cette difficult√© refl√®te un d√©fi majeur en reconnaissance d'images agricoles : distinguer les sympt√¥mes subtils de maladies sur des images prises dans des conditions naturelles variables, avec des arri√®re-plans complexes et des variations d'√©clairage. Difficult√©s d√©taill√©es par cat√©gorie Pr√©visionnel ‚Ä¢ Temps de pr√©processing sous-estim√© : Le nettoyage et l'homog√©n√©isation des multiples datasets (fusion de bases redondantes, correction des d√©s√©quilibres entre classes) ont n√©cessit√© significativem

‚óè Augmentation cibl√©e : Techniques d'augmentation sp√©cialis√©es par type de maladie (GANs, style transfer) ‚óè Donn√©es multi-modales : Int√©gration d'informations contextuelles (g√©olocalisation, saison, ‚Ä¶) Optimisations architecturales ‚óè Mod√®les hybrides : Combinaison CNN-RNN avec r√©seaux Liquid Time-Constant pour traitement temporel ‚óè Attention mechanisms : Int√©gration de m√©canismes d'attention pour focaliser sur les zones pathologiques ‚óè Architecture adaptative : Mod√®les capables d'ajuster leur co

‚Ä¢ Optimisation pour le d√©ploiement mobile : Apprentissage des techniques de compression et quantification de mod√®les pour l'usage sur smartphone Pertinence ‚óè Choix architecturaux : N√©cessit√© de r√©viser l'approche initiale face aux performances insuffisantes sur certaines classes, menant √† l'exploration de mod√®les alternatifs (SwinTransformer) ou l‚Äôutilisation de certaines images pr√©-retraitement (Cassave) ‚óè M√©triques d'√©valuation : Remise en question de l'accuracy comme m√©trique principale face 

================================================================================

[2025-08-10 22:11:31,378] INFO - üîç Re-ranking des 24 chunks pour : ¬´ R√©sume la pipeline d'entra√Ænement ¬ª
### Question
R√©sume la pipeline d'entra√Ænement

**Top‚ÄëK**: 6

### Top K chunks (rerank cos_sim)
- **#1** | score=0.8289 | id=`21ed7d65-1921-48ed-aef7-cbf9f2dc008b` | len=1440
  
> Optimisation  Nos mod√®les ont √©t√© optimis√©s en suivant 2 phases.   Phase 1  La premi√®re phase a repos√© sur :  ‚óè des corrections d‚Äôerreur : mesures de pr√©cision sur des images test et non les images d‚Äôentra√Ænement ; ‚óè des ‚Äú√©lagages‚Äù rapides de mod√®les jug√©s non pertinents ; ‚óè l‚Äôutilisation de techniques de fine-tuning : choix des ‚Äúoptimizers‚Äù, gel/d√©gel de couches des mod√®les po‚Ä¶

- **#2** | score=0.8248 | id=`4d1e3223-2113-4440-921a-71e343a99aec` | len=667
  
> ResNet50V2, EfficientNetV2M et Vit16 sous Keras  Pour ces 3 mod√®les, nous avons suivi le m√™me plan d‚Äôentra√Ænement suivant.  Phase d'Entra√Ænement Optimiseur Scheduler de Learning Rate Perte Callbacks D√©tails suppl√©mentaires Premier Entra√Ænement Adam CosineDecayRestarts en Fine tuning SparseFocalLoss (sans poids) earlystop, time_callback, printLR, model_checkpoint_callback  20 ep‚Ä¶

- **#3** | score=0.8230 | id=`06e8e6f5-fb8d-440e-bde8-7fa6d3d96e7b` | len=1065
  
> ‚Ä¢ Optimisation pour le d√©ploiement mobile : Apprentissage des techniques de compression et quantification de mod√®les pour l'usage sur smartphone Pertinence ‚óè Choix architecturaux : N√©cessit√© de r√©viser l'approche initiale face aux performances insuffisantes sur certaines classes, menant √† l'exploration de mod√®les alternatifs (SwinTransformer) ou l‚Äôutilisation de certaines image‚Ä¶

- **#4** | score=0.8228 | id=`d6a140cb-6f18-4419-a78d-ffea9910ba24` | len=1793
  
> Vision Transformer pure ViT16 Tr√®s Bon    Conclusion au terme de la Phase 1  Nous tirons de cette premi√®re phase deux enseignements: ‚óè La qualit√© de la pr√©cision semble souffrir de la classe Cassave : quel que soit le mod√®le employ√©, et malgr√© les efforts de fine-tuning, il semble qu‚Äôune difficult√© de reconnaissance subsiste pour cette classe. Cette difficult√© est selon intrins‚Ä¶

- **#5** | score=0.8128 | id=`8d9aba35-9f7c-4499-ab1b-36eb07c8a3bc` | len=1956
  
> ‚óè Augmentation cibl√©e : Techniques d'augmentation sp√©cialis√©es par type de maladie (GANs, style transfer) ‚óè Donn√©es multi-modales : Int√©gration d'informations contextuelles (g√©olocalisation, saison, ‚Ä¶) Optimisations architecturales ‚óè Mod√®les hybrides : Combinaison CNN-RNN avec r√©seaux Liquid Time-Constant pour traitement temporel ‚óè Attention mechanisms : Int√©gration de m√©canism‚Ä¶

- **#6** | score=0.8124 | id=`c757287b-8917-4635-b64d-32df6dd63755` | len=1660
  
> sup√©rieure.  ‚óè Profundit√© : Moins profond que ResNet50V2, mais beaucoup plus efficace pour les m√™mes performances.  ‚óè Performance : G√©n√©ralement plus rapide et plus efficace que ResNet50V2 pour la m√™me pr√©cision.  ‚óè Avantages : Tr√®s efficace en termes de taille du mod√®le et d'utilisation des ressources, il donne de bons r√©sultats m√™me avec des r√©seaux moins profonds.  ‚óè Inconv√©‚Ä¶


---
### Contexte concat√©n√© (troncature √©ventuelle)

Optimisation  Nos mod√®les ont √©t√© optimis√©s en suivant 2 phases.   Phase 1  La premi√®re phase a repos√© sur :  ‚óè des corrections d‚Äôerreur : mesures de pr√©cision sur des images test et non les images d‚Äôentra√Ænement ; ‚óè des ‚Äú√©lagages‚Äù rapides de mod√®les jug√©s non pertinents ; ‚óè l‚Äôutilisation de techniques de fine-tuning : choix des ‚Äúoptimizers‚Äù, gel/d√©gel de couches des mod√®les pour l‚Äôapprentissage, technique d‚Äôaugmentation de data, ajustement des learning rates et introduction de scheduler, modifi

ResNet50V2, EfficientNetV2M et Vit16 sous Keras  Pour ces 3 mod√®les, nous avons suivi le m√™me plan d‚Äôentra√Ænement suivant.  Phase d'Entra√Ænement Optimiseur Scheduler de Learning Rate Perte Callbacks D√©tails suppl√©mentaires Premier Entra√Ænement Adam CosineDecayRestarts en Fine tuning SparseFocalLoss (sans poids) earlystop, time_callback, printLR, model_checkpoint_callback 
20 epochs max en transfert learning, 5 epochs max en finetuning avec toutes les couches d√©g√©l√©es Deuxi√®me Entra√Ænement (Am√©li

‚Ä¢ Optimisation pour le d√©ploiement mobile : Apprentissage des techniques de compression et quantification de mod√®les pour l'usage sur smartphone Pertinence ‚óè Choix architecturaux : N√©cessit√© de r√©viser l'approche initiale face aux performances insuffisantes sur certaines classes, menant √† l'exploration de mod√®les alternatifs (SwinTransformer) ou l‚Äôutilisation de certaines images pr√©-retraitement (Cassave) ‚óè M√©triques d'√©valuation : Remise en question de l'accuracy comme m√©trique principale face 

Vision Transformer pure ViT16 Tr√®s Bon 
  Conclusion au terme de la Phase 1  Nous tirons de cette premi√®re phase deux enseignements: ‚óè La qualit√© de la pr√©cision semble souffrir de la classe Cassave : quel que soit le mod√®le employ√©, et malgr√© les efforts de fine-tuning, il semble qu‚Äôune difficult√© de reconnaissance subsiste pour cette classe. Cette difficult√© est selon intrins√®quement li√© √† la qualit√© des images et aux probl√®mes apparents de labellisation. Nous nous interrogeons donc sur l‚Äôaban

‚óè Augmentation cibl√©e : Techniques d'augmentation sp√©cialis√©es par type de maladie (GANs, style transfer) ‚óè Donn√©es multi-modales : Int√©gration d'informations contextuelles (g√©olocalisation, saison, ‚Ä¶) Optimisations architecturales ‚óè Mod√®les hybrides : Combinaison CNN-RNN avec r√©seaux Liquid Time-Constant pour traitement temporel ‚óè Attention mechanisms : Int√©gration de m√©canismes d'attention pour focaliser sur les zones pathologiques ‚óè Architecture adaptative : Mod√®les capables d'ajuster leur co

sup√©rieure.  ‚óè Profundit√© : Moins profond que ResNet50V2, mais beaucoup plus efficace pour les m√™mes performances.  ‚óè Performance : G√©n√©ralement plus rapide et plus efficace que ResNet50V2 pour la m√™me pr√©cision.  ‚óè Avantages : Tr√®s efficace en termes de taille du mod√®le et d'utilisation des ressources, il donne de bons r√©sultats m√™me avec des r√©seaux moins profonds.  ‚óè Inconv√©nients : Moins √©prouv√© que ResNet50V2 dans certaines configurations.  EfficientNetV2M :  ‚óè Architecture : Une am√©liorati

================================================================================

[2025-08-10 22:12:17,915] INFO - üîç Re-ranking des 24 chunks pour : ¬´ Quelles sont les m√©triques finales ? ¬ª
### Question
Quelles sont les m√©triques finales ?

**Top‚ÄëK**: 1

### Top K chunks (rerank cos_sim)
- **#1** | score=0.8149 | id=`74a8d50d-c7b8-4978-88a0-ac51ec693c19` | len=1678
  
> Conclusions pr√©-mod√©lisation   Nous disposons au terme de cette √©tape d‚Äôun fichier homog√®ne en termes de qualit√© d‚Äôimages, d‚Äôune quantit√© a priori suffisante pour appliquer un algorithme de reconnaissance, au d√©s√©quilibre entre classes moins marqu√© que sur les donn√©es d‚Äôorigine, et qui affiche d√©j√† quelques variables discriminantes sur l‚Äôune des deux variables cibles. Partie 4 ‚Ä¶


---
### Contexte concat√©n√© (troncature √©ventuelle)

Conclusions pr√©-mod√©lisation   Nous disposons au terme de cette √©tape d‚Äôun fichier homog√®ne en termes de qualit√© d‚Äôimages, d‚Äôune quantit√© a priori suffisante pour appliquer un algorithme de reconnaissance, au d√©s√©quilibre entre classes moins marqu√© que sur les donn√©es d‚Äôorigine, et qui affiche d√©j√† quelques variables discriminantes sur l‚Äôune des deux variables cibles. Partie 4 : Mod√©lisation  Classification du probl√®me  Type de probl√®me de machine learning  La cible du projet est d‚Äôoffrir √† un i
