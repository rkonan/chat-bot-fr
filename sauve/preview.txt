(llamavenv) rkonan@rkonan-ThinkPad-T460:~/chatbot-project$ python test_preview.py   --vector vectordb/chunks.pkl   --index  vectordb/index.fais
s   --k 8   --q "Quels traitements d'images ont √©t√© appliqu√©s ?"      "R√©sume la pipeline d'entra√Ænement"      "Quelles sont les m√©triques fina
les ?"
[2025-08-10 21:37:02,916] INFO - üì¶ Initialisation du moteur (hybride, lazy, no-opts)...
[2025-08-10 21:37:02,916] INFO - ‚úÖ Moteur pr√™t (FAISS/chunks non charg√©s).
[2025-08-10 21:37:02,916] INFO - ‚è≥ Chargement lazy des donn√©es RAG (FAISS + chunks + embeddings)...
/home/rkonan/chatbot-project/llamavenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
[2025-08-10 21:38:02,571] INFO - ‚úÖ RAG charg√© en 59.65s (lazy).
[2025-08-10 21:38:02,765] INFO - üîç Re-ranking des 8 chunks pour : ¬´ Quels traitements d'images ont √©t√© appliqu√©s ? ¬ª
### Question
Quels traitements d'images ont √©t√© appliqu√©s ?

**Top‚ÄëK**: 8

### Top K chunks (rerank cos_sim)
- **#1** | score=0.8370 | id=`a82ca2bd-db0f-4fe6-807d-3e74e358f3eb` | len=1531
  
> que les images sont devenues plus nettes et moins floues apr√®s avoir subi les ajustements sur la nettet√©.  Analyse du contraste et de la luminosit√© avant et apr√®s retraitement   Les bo√Ætes √† moustaches montrent que le retraitement a am√©lior√© la qualit√© des images en r√©duisant les valeurs aberrantes. Pour le contraste, la m√©diane est rest√©e stable, mais les valeurs tr√®s faibles ‚Ä¶

- **#2** | score=0.8308 | id=`61a5ee6b-58db-4d55-9586-6fb005d63ba1` | len=1787
  
> A partir du dataframe initial, on parcourt l‚Äôensemble des images gr√¢ce au FilePath pour appliquer nos crit√®res de qualit√© et cr√©er un dataframe (df_high_quality) r√©unissant uniquement les images qui passent le test.   Ceux ne passant pas les crit√®res de qualit√© vont √™tre int√©gr√© √† un dataframe diff√©rent (df_low_quality) pour √™tre trait√©.  Transformations des donn√©es  Traitement‚Ä¶

- **#3** | score=0.8287 | id=`d57195cb-0495-4e57-8b21-d0fb2e3893d8` | len=1316
  
> 5. Redimensionnement de l‚Äôimage La fonction `resize_image(image, width, height)` redimensionne les images √† une taille sp√©cifi√©e (ici, 256x256 pixels). Cette op√©ration est r√©alis√©e avec la m√©thode `resize()` de PIL en utilisant l'algorithme `LANCZOS`, qui permet de pr√©server la qualit√© de l'image lors du redimensionnement.  6. Configuration des param√®tres globaux Les facteurs d‚Ä¶

- **#4** | score=0.8215 | id=`87b8c08b-a71a-458a-97b7-94f06e94068c` | len=591
  
> Elle sera ensuite retrait√©e (format JPEG, RGB, redimensionnement et √©ventuellement retraitement du niveau de flou afin de faciliter le diagnostic). Ce premier algorithme de classification, entra√Æn√© sur la base totale des images d√©crite en page 14 et de m√©ta-donn√©es pouvant y √™tre rattach√©es aura √©t√© test√© sur une base constitu√©e de 20% des images concern√©es avec un objectif d‚Äôa‚Ä¶

- **#5** | score=0.8194 | id=`e6b05cd6-83a1-4ad3-8290-e30e160d373e` | len=1956
  
> ‚óè Augmentation cibl√©e : Techniques d'augmentation sp√©cialis√©es par type de maladie (GANs, style transfer) ‚óè Donn√©es multi-modales : Int√©gration d'informations contextuelles (g√©olocalisation, saison, ‚Ä¶) Optimisations architecturales ‚óè Mod√®les hybrides : Combinaison CNN-RNN avec r√©seaux Liquid Time-Constant pour traitement temporel ‚óè Attention mechanisms : Int√©gration de m√©canism‚Ä¶

- **#6** | score=0.8162 | id=`db687eaa-20bf-4035-8332-58e2a3edf130` | len=1065
  
> ‚Ä¢ Optimisation pour le d√©ploiement mobile : Apprentissage des techniques de compression et quantification de mod√®les pour l'usage sur smartphone Pertinence ‚óè Choix architecturaux : N√©cessit√© de r√©viser l'approche initiale face aux performances insuffisantes sur certaines classes, menant √† l'exploration de mod√®les alternatifs (SwinTransformer) ou l‚Äôutilisation de certaines image‚Ä¶

- **#7** | score=0.8157 | id=`1b904edf-2b2c-4ac9-9fd5-25d4dc8789eb` | len=1630
  
> Autres ‚óè Incompatibilit√©s techniques : Probl√®mes de compatibilit√© entre TensorFlow 2.19 et certains outils d'interpr√©tation (SHAP DeepExplainer, GradCam) ‚óè Migration entre frameworks : Passage de FastAI vers TensorFlow pour faciliter l'int√©gration Firebase, n√©cessitant la r√©-impl√©mentation de certains mod√®les Bilan Contribution principale dans l'atteinte des objectifs Notre con‚Ä¶

- **#8** | score=0.8146 | id=`9a407713-6ac7-4838-96ae-cafb35c1ff11` | len=740
  
> Dans le dataframe des images de bonnes qualit√©s, il y a 79 599 images, dont les trois premi√®res esp√®ces repr√©sentent + 45% du total.  Distribution des esp√®ces dans le dataframe ‚Äúlow quality‚Äù      Il y a 47 069 images, on peut remarquer que l‚Äôensemble des images des esp√®ces cassave, riz, et sucre de canne ne sont pr√©sentes que sur le dataframe de mauvaise qualit√©.  Mesure d‚Äôam√©l‚Ä¶


---
### Contexte concat√©n√© (troncature √©ventuelle)

que les images sont devenues plus nettes et moins floues apr√®s avoir subi les ajustements sur la nettet√©.  Analyse du contraste et de la luminosit√© avant et apr√®s retraitement 
 Les bo√Ætes √† moustaches montrent que le retraitement a am√©lior√© la qualit√© des images en r√©duisant les valeurs aberrantes. Pour le contraste, la m√©diane est rest√©e stable, mais les valeurs tr√®s faibles de contraste ont √©t√© corrig√©es, et la gamme des valeurs s'est √©largie. De m√™me, pour la luminosit√©, la m√©diane est incha

A partir du dataframe initial, on parcourt l‚Äôensemble des images gr√¢ce au FilePath pour appliquer nos crit√®res de qualit√© et cr√©er un dataframe (df_high_quality) r√©unissant uniquement les images qui passent le test.   Ceux ne passant pas les crit√®res de qualit√© vont √™tre int√©gr√© √† un dataframe diff√©rent (df_low_quality) pour √™tre trait√©.  Transformations des donn√©es  Traitement des images Plusieurs traitements sont appliqu√©s aux images dans le but d‚Äôam√©liorer leur qualit√©. Les traitements inclue

5. Redimensionnement de l‚Äôimage La fonction `resize_image(image, width, height)` redimensionne les images √† une taille sp√©cifi√©e (ici, 256x256 pixels). Cette op√©ration est r√©alis√©e avec la m√©thode `resize()` de PIL en utilisant l'algorithme `LANCZOS`, qui permet de pr√©server la qualit√© de l'image lors du redimensionnement.  6. Configuration des param√®tres globaux Les facteurs de traitement sont d√©finis avant le traitement : ‚óè `brightness_factor` : Ajuste la luminosit√© (ici fix√© √† 0.8 pour une l√©

Elle sera ensuite retrait√©e (format JPEG, RGB, redimensionnement et √©ventuellement retraitement du niveau de flou afin de faciliter le diagnostic). Ce premier algorithme de classification, entra√Æn√© sur la base totale des images d√©crite en page 14 et de m√©ta-donn√©es pouvant y √™tre rattach√©es aura √©t√© test√© sur une base constitu√©e de 20% des images concern√©es avec un objectif d‚Äôaccuracy de 95%. La base totale des images aura √©t√© probablement corrig√©e afin de minimiser les d√©s√©quilibres entre class

‚óè Augmentation cibl√©e : Techniques d'augmentation sp√©cialis√©es par type de maladie (GANs, style transfer) ‚óè Donn√©es multi-modales : Int√©gration d'informations contextuelles (g√©olocalisation, saison, ‚Ä¶) Optimisations architecturales ‚óè Mod√®les hybrides : Combinaison CNN-RNN avec r√©seaux Liquid Time-Constant pour traitement temporel ‚óè Attention mechanisms : Int√©gration de m√©canismes d'attention pour focaliser sur les zones pathologiques ‚óè Architecture adaptative : Mod√®les capables d'ajuster leur co

‚Ä¢ Optimisation pour le d√©ploiement mobile : Apprentissage des techniques de compression et quantification de mod√®les pour l'usage sur smartphone Pertinence ‚óè Choix architecturaux : N√©cessit√© de r√©viser l'approche initiale face aux performances insuffisantes sur certaines classes, menant √† l'exploration de mod√®les alternatifs (SwinTransformer) ou l‚Äôutilisation de certaines images pr√©-retraitement (Cassave) ‚óè M√©triques d'√©valuation : Remise en question de l'accuracy comme m√©trique principale face 

Autres ‚óè Incompatibilit√©s techniques : Probl√®mes de compatibilit√© entre TensorFlow 2.19 et certains outils d'interpr√©tation (SHAP DeepExplainer, GradCam) ‚óè Migration entre frameworks : Passage de FastAI vers TensorFlow pour faciliter l'int√©gration Firebase, n√©cessitant la r√©-impl√©mentation de certains mod√®les Bilan Contribution principale dans l'atteinte des objectifs Notre contribution principale r√©side dans le d√©veloppement d'une pipeline compl√®te de traitement et de classification d'images de

Dans le dataframe des images de bonnes qualit√©s, il y a 79 599 images, dont les trois premi√®res esp√®ces repr√©sentent + 45% du total.  Distribution des esp√®ces dans le dataframe ‚Äúlow quality‚Äù  
   Il y a 47 069 images, on peut remarquer que l‚Äôensemble des images des esp√®ces cassave, riz, et sucre de canne ne sont pr√©sentes que sur le dataframe de mauvaise qualit√©.  Mesure d‚Äôam√©lioration de la qualit√© des images  Distribution du flou avant/apr√®s retraitements 
 D'apr√®s la visualisation, la densit√©

================================================================================

[2025-08-10 21:38:09,047] INFO - üîç Re-ranking des 8 chunks pour : ¬´ R√©sume la pipeline d'entra√Ænement ¬ª
### Question
R√©sume la pipeline d'entra√Ænement

**Top‚ÄëK**: 8

### Top K chunks (rerank cos_sim)
- **#1** | score=0.8311 | id=`6f53dedd-a191-40d4-a87b-65194b26e951` | len=49
  
> Comparaison du f1-score par classe et par mod√®les

- **#2** | score=0.8289 | id=`a2bcbbc5-d151-424c-9c0c-0f01d1ff7f81` | len=1440
  
> Optimisation  Nos mod√®les ont √©t√© optimis√©s en suivant 2 phases.   Phase 1  La premi√®re phase a repos√© sur :  ‚óè des corrections d‚Äôerreur : mesures de pr√©cision sur des images test et non les images d‚Äôentra√Ænement ; ‚óè des ‚Äú√©lagages‚Äù rapides de mod√®les jug√©s non pertinents ; ‚óè l‚Äôutilisation de techniques de fine-tuning : choix des ‚Äúoptimizers‚Äù, gel/d√©gel de couches des mod√®les po‚Ä¶

- **#3** | score=0.8248 | id=`1b16209e-1da0-46e8-9245-efb5de1eabfb` | len=667
  
> ResNet50V2, EfficientNetV2M et Vit16 sous Keras  Pour ces 3 mod√®les, nous avons suivi le m√™me plan d‚Äôentra√Ænement suivant.  Phase d'Entra√Ænement Optimiseur Scheduler de Learning Rate Perte Callbacks D√©tails suppl√©mentaires Premier Entra√Ænement Adam CosineDecayRestarts en Fine tuning SparseFocalLoss (sans poids) earlystop, time_callback, printLR, model_checkpoint_callback  20 ep‚Ä¶

- **#4** | score=0.8230 | id=`db687eaa-20bf-4035-8332-58e2a3edf130` | len=1065
  
> ‚Ä¢ Optimisation pour le d√©ploiement mobile : Apprentissage des techniques de compression et quantification de mod√®les pour l'usage sur smartphone Pertinence ‚óè Choix architecturaux : N√©cessit√© de r√©viser l'approche initiale face aux performances insuffisantes sur certaines classes, menant √† l'exploration de mod√®les alternatifs (SwinTransformer) ou l‚Äôutilisation de certaines image‚Ä¶

- **#5** | score=0.8228 | id=`6684463c-bc91-4f8f-aaeb-2aec2c0a70bd` | len=1793
  
> Vision Transformer pure ViT16 Tr√®s Bon    Conclusion au terme de la Phase 1  Nous tirons de cette premi√®re phase deux enseignements: ‚óè La qualit√© de la pr√©cision semble souffrir de la classe Cassave : quel que soit le mod√®le employ√©, et malgr√© les efforts de fine-tuning, il semble qu‚Äôune difficult√© de reconnaissance subsiste pour cette classe. Cette difficult√© est selon intrins‚Ä¶

- **#6** | score=0.8212 | id=`d034ae1f-d754-44d0-8682-69580038ea02` | len=1863
  
> Processus de re-labellisation     ‚Ä¢ Les images du premier d√©cile de score ont √©t√© re-labellis√©es automatiquement.     ‚Ä¢ Le nouveau label correspond √† la classe pr√©dite par le soft voting, consid√©r√©e comme plus fiable que le label d‚Äôorigine.     ‚Ä¢ Les autres images ont conserv√© leur annotation initiale. Objectifs     ‚Ä¢ Corriger les labels potentiellement erron√©s.     ‚Ä¢ Maintenir‚Ä¶

- **#7** | score=0.8168 | id=`5037052a-cfbf-4a63-a0a7-727ebf799839` | len=1293
  
> ‚Ä¢ Phase d'interpr√©tation des mod√®les : L'utilisation d'outils comme GradCam et SHAP s'est r√©v√©l√©e plus complexe techniquement qu'anticip√©, avec des incompatibilit√©s entre certaines architectures (EfficientNetV2M) et les outils d'explicabilit√© Jeux de donn√©es ‚Ä¢ Redondance non d√©tect√©e initialement : D√©couverte tardive que 3 des 4 datasets principaux provenaient de la m√™me source‚Ä¶

- **#8** | score=0.8162 | id=`6ea78435-5b1a-4fab-8f1b-4f98ded83e2a` | len=82
  
> Tableau 2 : Performances sur le sous-ensemble Cassava     6. Analyse des r√©sultats


---
### Contexte concat√©n√© (troncature √©ventuelle)

Comparaison du f1-score par classe et par mod√®les

Optimisation  Nos mod√®les ont √©t√© optimis√©s en suivant 2 phases.   Phase 1  La premi√®re phase a repos√© sur :  ‚óè des corrections d‚Äôerreur : mesures de pr√©cision sur des images test et non les images d‚Äôentra√Ænement ; ‚óè des ‚Äú√©lagages‚Äù rapides de mod√®les jug√©s non pertinents ; ‚óè l‚Äôutilisation de techniques de fine-tuning : choix des ‚Äúoptimizers‚Äù, gel/d√©gel de couches des mod√®les pour l‚Äôapprentissage, technique d‚Äôaugmentation de data, ajustement des learning rates et introduction de scheduler, modifi

ResNet50V2, EfficientNetV2M et Vit16 sous Keras  Pour ces 3 mod√®les, nous avons suivi le m√™me plan d‚Äôentra√Ænement suivant.  Phase d'Entra√Ænement Optimiseur Scheduler de Learning Rate Perte Callbacks D√©tails suppl√©mentaires Premier Entra√Ænement Adam CosineDecayRestarts en Fine tuning SparseFocalLoss (sans poids) earlystop, time_callback, printLR, model_checkpoint_callback 
20 epochs max en transfert learning, 5 epochs max en finetuning avec toutes les couches d√©g√©l√©es Deuxi√®me Entra√Ænement (Am√©li

‚Ä¢ Optimisation pour le d√©ploiement mobile : Apprentissage des techniques de compression et quantification de mod√®les pour l'usage sur smartphone Pertinence ‚óè Choix architecturaux : N√©cessit√© de r√©viser l'approche initiale face aux performances insuffisantes sur certaines classes, menant √† l'exploration de mod√®les alternatifs (SwinTransformer) ou l‚Äôutilisation de certaines images pr√©-retraitement (Cassave) ‚óè M√©triques d'√©valuation : Remise en question de l'accuracy comme m√©trique principale face 

Vision Transformer pure ViT16 Tr√®s Bon 
  Conclusion au terme de la Phase 1  Nous tirons de cette premi√®re phase deux enseignements: ‚óè La qualit√© de la pr√©cision semble souffrir de la classe Cassave : quel que soit le mod√®le employ√©, et malgr√© les efforts de fine-tuning, il semble qu‚Äôune difficult√© de reconnaissance subsiste pour cette classe. Cette difficult√© est selon intrins√®quement li√© √† la qualit√© des images et aux probl√®mes apparents de labellisation. Nous nous interrogeons donc sur l‚Äôaban

Processus de re-labellisation     ‚Ä¢ Les images du premier d√©cile de score ont √©t√© re-labellis√©es automatiquement.     ‚Ä¢ Le nouveau label correspond √† la classe pr√©dite par le soft voting, consid√©r√©e comme plus fiable que le label d‚Äôorigine.     ‚Ä¢ Les autres images ont conserv√© leur annotation initiale. Objectifs     ‚Ä¢ Corriger les labels potentiellement erron√©s.     ‚Ä¢ Maintenir la taille du dataset en rempla√ßant les √©tiquettes douteuses.     ‚Ä¢ Exploiter la confiance collective des mod√®les pour g

‚Ä¢ Phase d'interpr√©tation des mod√®les : L'utilisation d'outils comme GradCam et SHAP s'est r√©v√©l√©e plus complexe techniquement qu'anticip√©, avec des incompatibilit√©s entre certaines architectures (EfficientNetV2M) et les outils d'explicabilit√© Jeux de donn√©es ‚Ä¢ Redondance non d√©tect√©e initialement : D√©couverte tardive que 3 des 4 datasets principaux provenaient de la m√™me source originale, r√©duisant la diversit√© r√©elle des donn√©es ‚Ä¢ D√©s√©quilibre s√©v√®re : Surrepr√©sentation massive des tomates (13 

Tableau 2 : Performances sur le sous-ensemble Cassava 
 
 6. Analyse des r√©sultats

================================================================================

[2025-08-10 21:38:14,026] INFO - üîç Re-ranking des 8 chunks pour : ¬´ Quelles sont les m√©triques finales ? ¬ª
### Question
Quelles sont les m√©triques finales ?

**Top‚ÄëK**: 8

### Top K chunks (rerank cos_sim)
- **#1** | score=0.8149 | id=`57311881-65a8-4740-87e5-63f267afdab3` | len=1678
  
> Conclusions pr√©-mod√©lisation   Nous disposons au terme de cette √©tape d‚Äôun fichier homog√®ne en termes de qualit√© d‚Äôimages, d‚Äôune quantit√© a priori suffisante pour appliquer un algorithme de reconnaissance, au d√©s√©quilibre entre classes moins marqu√© que sur les donn√©es d‚Äôorigine, et qui affiche d√©j√† quelques variables discriminantes sur l‚Äôune des deux variables cibles. Partie 4 ‚Ä¶

- **#2** | score=0.8071 | id=`49f2f0f7-0de0-44e1-a75d-e76168da1005` | len=439
  
> M√©triques secondaires  Loss : Nous avons √©galement jaug√© la rapidit√© de la convergence du mod√®le en suivant la notion de loss √† chaque √©poque de l‚Äôapprentissage.   Selon les mod√®les et afin de nous assurer, malgr√© le faible d√©s√©quilibre de classes, que les classes les moins repr√©sent√©es soient correctement trait√©es, nous avons observ√© dans certains cas quelle √©tait la k-√®me Acc‚Ä¶

- **#3** | score=0.8025 | id=`07fe1c8f-5089-4f94-a5c5-eaa2d8ae5a20` | len=1574
  
> Les m√©triques pr√©cision, recall et F1-score gagnent environ 1pt pour atteindre 95% et 98% pour respectivement EfficientNetB0 et VGG12. Ce dernier est donc plus performant, ce qui √©limine le premier mod√®le. Bien que dans l‚Äôapprentissage de ces deux mod√®les, les classes ‚ÄúCassava‚Äù aient √©t√© exclues, on note des classes de tomates moins bien pr√©dites telles que celles atteintes des‚Ä¶

- **#4** | score=0.7998 | id=`f1a22e98-06ef-4cf2-b379-8699362605a0` | len=2894
  
> M√©triques de performance utilis√©es pour comparer les mod√®les ............................................... 18 M√©trique principale ................................................................................................................................ 18 M√©triques secondaires ..............................................................................................‚Ä¶

- **#5** | score=0.7986 | id=`619cbc76-7130-411c-9a4c-13f43ddd39d2` | len=962
  
> Comparaison des performances des m√©thodes d‚Äôensemblage  Nous avons explor√© deux approches principales pour combiner les mod√®les : Soft Voting (vote pond√©r√© par les probabilit√©s) : chaque mod√®le contribue √† la pr√©diction finale via sa distribution de probabilit√©. Nous avons initialement utilis√© une pond√©ration √©quivalente pour chaque mod√®le. Une √©tude syst√©matique des coefficien‚Ä¶

- **#6** | score=0.7984 | id=`2a054425-bc69-4bc3-a7f5-a3dc6dae9a6f` | len=391
  
> Les 3 mod√®les plafonnent √† 0.95 apr√®s le fine tuning. En effet, les r√©sultats de la classification  des images de l‚Äôesp√®ce cassava sont tr√®s mauvais sur les trois mod√®les. Il faudra dans une seconde √©tape √©tudier en d√©tail ces images.   Exemple de classification report avec un zoom sur l'esp√®ce cassava.     Graphe comparatif de l‚Äô√©volutions de la pr√©cision et de la perte des tr‚Ä¶

- **#7** | score=0.7976 | id=`ce71ecda-93f4-407f-a7ec-84fe81a92cf8` | len=1201
  
> 3- Torch   Description des mod√®les  2 mod√®les ont √©t√© test√©s sous Torch :   ‚óè 1 mod√®le simple avec Transfer Learning, bas√© sur le mod√®le pr√©-entra√Æn√© MobileNetV2, dont les couches interm√©diaires sont neutralis√©es et seule la derni√®re couche est ajust√©e aux classes √† pr√©dire, puis r√©-entrain√©e. Le choix s‚Äôest port√© sur ce mod√®le car il est r√©put√© √™tre id√©al pour des applications‚Ä¶

- **#8** | score=0.7958 | id=`7428bf68-6c0d-421f-8187-c85908f4a39d` | len=232
  
> Deux tableaux sont pr√©sent√©s :     ‚Ä¢ Le premier montre l‚Äô√©volution des performances globales.     ‚Ä¢ Le second est centr√© sur les performances sp√©cifiques aux classes Cassava.  Tableau 1 : Performances globales (Accuracy et F1-score)


---
### Contexte concat√©n√© (troncature √©ventuelle)

Conclusions pr√©-mod√©lisation   Nous disposons au terme de cette √©tape d‚Äôun fichier homog√®ne en termes de qualit√© d‚Äôimages, d‚Äôune quantit√© a priori suffisante pour appliquer un algorithme de reconnaissance, au d√©s√©quilibre entre classes moins marqu√© que sur les donn√©es d‚Äôorigine, et qui affiche d√©j√† quelques variables discriminantes sur l‚Äôune des deux variables cibles. Partie 4 : Mod√©lisation  Classification du probl√®me  Type de probl√®me de machine learning  La cible du projet est d‚Äôoffrir √† un i

M√©triques secondaires  Loss : Nous avons √©galement jaug√© la rapidit√© de la convergence du mod√®le en suivant la notion de loss √† chaque √©poque de l‚Äôapprentissage.   Selon les mod√®les et afin de nous assurer, malgr√© le faible d√©s√©quilibre de classes, que les classes les moins repr√©sent√©es soient correctement trait√©es, nous avons observ√© dans certains cas quelle √©tait la k-√®me Accuracy la plus faible parmi les classes propos√©es au mod√®le.

Les m√©triques pr√©cision, recall et F1-score gagnent environ 1pt pour atteindre 95% et 98% pour respectivement EfficientNetB0 et VGG12. Ce dernier est donc plus performant, ce qui √©limine le premier mod√®le. Bien que dans l‚Äôapprentissage de ces deux mod√®les, les classes ‚ÄúCassava‚Äù aient √©t√© exclues, on note des classes de tomates moins bien pr√©dites telles que celles atteintes des maladies ‚ÄúMosaic Virus‚Äù et ‚ÄúSpider Mites‚Äù (Pr√©cision : 73%, Recall : 98%, F1-Score : 84%). On note d‚Äôailleurs qu‚Äô√† l‚Äôoe

M√©triques de performance utilis√©es pour comparer les mod√®les ............................................... 18 M√©trique principale ................................................................................................................................ 18 M√©triques secondaires ........................................................................................................................... 18 Choix du mod√®le et optimisation .......................................................

Comparaison des performances des m√©thodes d‚Äôensemblage  Nous avons explor√© deux approches principales pour combiner les mod√®les : Soft Voting (vote pond√©r√© par les probabilit√©s) : chaque mod√®le contribue √† la pr√©diction finale via sa distribution de probabilit√©. Nous avons initialement utilis√© une pond√©ration √©quivalente pour chaque mod√®le. Une √©tude syst√©matique des coefficients de pond√©ration n‚Äôa pas mis en √©vidence de combinaison significativement meilleure que l‚Äô√©quipond√©ration. Cette m√©thod

Les 3 mod√®les plafonnent √† 0.95 apr√®s le fine tuning. En effet, les r√©sultats de la classification  des images de l‚Äôesp√®ce cassava sont tr√®s mauvais sur les trois mod√®les. Il faudra dans une seconde √©tape √©tudier en d√©tail ces images.   Exemple de classification report avec un zoom sur l'esp√®ce cassava.  
  Graphe comparatif de l‚Äô√©volutions de la pr√©cision et de la perte des trois mod√®les

3- Torch   Description des mod√®les  2 mod√®les ont √©t√© test√©s sous Torch :   ‚óè 1 mod√®le simple avec Transfer Learning, bas√© sur le mod√®le pr√©-entra√Æn√© MobileNetV2, dont les couches interm√©diaires sont neutralis√©es et seule la derni√®re couche est ajust√©e aux classes √† pr√©dire, puis r√©-entrain√©e. Le choix s‚Äôest port√© sur ce mod√®le car il est r√©put√© √™tre id√©al pour des applications embarqu√©es sur mobile, impliquant des contraintes de calcul (puissance limit√©e du mat√©riel) ou n√©cessitant un fonctionn

Deux tableaux sont pr√©sent√©s :     ‚Ä¢ Le premier montre l‚Äô√©volution des performances globales.     ‚Ä¢ Le second est centr√© sur les performances sp√©cifiques aux classes Cassava.  Tableau 1 : Performances globales (Accuracy et F1-score)

================================================================================