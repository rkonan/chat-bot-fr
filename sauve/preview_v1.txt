(llamavenv) rkonan@rkonan-ThinkPad-T460:~/chatbot-project$ python test_preview.py   --vector vectordb/chunks.pkl   --index  vectordb/index.faiss   --k 8   --q "Quels traitements d'images ont √©t√© appliqu√©s ?"      "R√©sume la pipeline d'entra√Ænement"      "Quelles sont les m√©triques finales ?"
[2025-08-10 22:01:55,848] INFO - üì¶ Initialisation du moteur (hybride, lazy, no-opts)...
[2025-08-10 22:01:55,849] INFO - ‚úÖ Moteur pr√™t (FAISS/chunks non charg√©s).
[2025-08-10 22:01:55,849] INFO - ‚è≥ Chargement lazy des donn√©es RAG (FAISS + chunks + embeddings)...
/home/rkonan/chatbot-project/llamavenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
[2025-08-10 22:02:50,720] INFO - ‚úÖ RAG charg√© en 54.87s (lazy).
[2025-08-10 22:02:50,821] INFO - üîç Re-ranking des 24 chunks pour : ¬´ Quels traitements d'images ont √©t√© appliqu√©s ? ¬ª
### Question
Quels traitements d'images ont √©t√© appliqu√©s ?

**Top‚ÄëK**: 8

### Top K chunks (rerank cos_sim)
- **#1** | score=0.8157 | id=`867088fa-9a44-426f-b62d-753121ec7317` | len=1630
  
> Autres ‚óè Incompatibilit√©s techniques : Probl√®mes de compatibilit√© entre TensorFlow 2.19 et certains outils d'interpr√©tation (SHAP DeepExplainer, GradCam) ‚óè Migration entre frameworks : Passage de FastAI vers TensorFlow pour faciliter l'int√©gration Firebase, n√©cessitant la r√©-impl√©mentation de certains mod√®les Bilan Contribution principale dans l'atteinte des objectifs Notre con‚Ä¶

- **#2** | score=0.8074 | id=`abc9f8c5-2c62-4981-b64e-b61f4ba79252` | len=235
  
> D‚Äôapr√®s nos outils d‚Äôinterpr√©tation, on remarque que les saillances d√©signent bien les parties des images importantes pour chacune des classes. Elle reconna√Æt les contours des plantes et les diff√©rences de couleurs issues des maladies.

- **#3** | score=0.8114 | id=`93131da9-50f6-45c7-bb09-e5ce05042c31` | len=1005
  
> La photographie retrait√©e, ou la photographie d‚Äôorigine subissant de nouveaux filtres, sera soumise √† un second algorithme de classification, entra√Æn√© sur la base totale des images d√©crite en page 14 et de m√©ta-donn√©es pouvant y √™tre rattach√©es (telles que le niveau de bleu dans l‚Äôimage qui est un premier pr√©dicteur du caract√®re malade ou non de la plante) et test√© sur une base‚Ä¶

- **#4** | score=0.8146 | id=`046e3ca7-bc7f-4d0b-937b-3a02b9f01a4b` | len=740
  
> Dans le dataframe des images de bonnes qualit√©s, il y a 79 599 images, dont les trois premi√®res esp√®ces repr√©sentent + 45% du total.  Distribution des esp√®ces dans le dataframe ‚Äúlow quality‚Äù      Il y a 47 069 images, on peut remarquer que l‚Äôensemble des images des esp√®ces cassave, riz, et sucre de canne ne sont pr√©sentes que sur le dataframe de mauvaise qualit√©.  Mesure d‚Äôam√©l‚Ä¶

- **#5** | score=0.8090 | id=`5d134f24-e559-4fb9-a9e0-f1b6eb7903e9` | len=1777
  
> Principe     ‚Ä¢ Les classes minoritaires (Healthy, Bacterial blight, Brown streak disease, Green mottle) ont √©t√© massivement augment√©es.     ‚Ä¢ L‚Äôobjectif √©tait d‚Äôatteindre un volume comparable √† la classe majoritaire (Cassava Mosaic Disease).     ‚Ä¢ Les techniques utilis√©es incluent : rotations, flips, changements de luminosit√©, contrastes, translations, etc. Objectifs     ‚Ä¢ Appo‚Ä¶

- **#6** | score=0.8370 | id=`489374cd-b26e-4f44-8db4-340225051898` | len=1531
  
> que les images sont devenues plus nettes et moins floues apr√®s avoir subi les ajustements sur la nettet√©.  Analyse du contraste et de la luminosit√© avant et apr√®s retraitement   Les bo√Ætes √† moustaches montrent que le retraitement a am√©lior√© la qualit√© des images en r√©duisant les valeurs aberrantes. Pour le contraste, la m√©diane est rest√©e stable, mais les valeurs tr√®s faibles ‚Ä¶

- **#7** | score=0.8287 | id=`d3072c99-e985-4e32-8638-335a20e96ea3` | len=1316
  
> 5. Redimensionnement de l‚Äôimage La fonction `resize_image(image, width, height)` redimensionne les images √† une taille sp√©cifi√©e (ici, 256x256 pixels). Cette op√©ration est r√©alis√©e avec la m√©thode `resize()` de PIL en utilisant l'algorithme `LANCZOS`, qui permet de pr√©server la qualit√© de l'image lors du redimensionnement.  6. Configuration des param√®tres globaux Les facteurs d‚Ä¶

- **#8** | score=0.8038 | id=`be532fbd-3fc6-47b9-87f6-32b48aac66d0` | len=1569
  
> ‚óè Fichier d‚Äôimages de feuilles d‚Äôarbres fruitiers, de l√©gumineuses et de c√©r√©ales, malades ou saines ‚óè Dataset d‚Äôentra√Ænement de 43.456 images ‚óè Dataset de test de 10.849 images ‚óè Volum√©tries restreintes aux images d‚Äôesp√®ces v√©g√©tales : 100%  https://www.kaggle.com/abdallahalidev/plantvillage-dataset ‚óè Fichier d‚Äôimages de feuilles d‚Äôarbres fruitiers, de l√©gumineuses et de c√©r√©a‚Ä¶


---
### Contexte concat√©n√© (troncature √©ventuelle)

Autres ‚óè Incompatibilit√©s techniques : Probl√®mes de compatibilit√© entre TensorFlow 2.19 et certains outils d'interpr√©tation (SHAP DeepExplainer, GradCam) ‚óè Migration entre frameworks : Passage de FastAI vers TensorFlow pour faciliter l'int√©gration Firebase, n√©cessitant la r√©-impl√©mentation de certains mod√®les Bilan Contribution principale dans l'atteinte des objectifs Notre contribution principale r√©side dans le d√©veloppement d'une pipeline compl√®te de traitement et de classification d'images de

D‚Äôapr√®s nos outils d‚Äôinterpr√©tation, on remarque que les saillances d√©signent bien les parties des images importantes pour chacune des classes. Elle reconna√Æt les contours des plantes et les diff√©rences de couleurs issues des maladies.

La photographie retrait√©e, ou la photographie d‚Äôorigine subissant de nouveaux filtres, sera soumise √† un second algorithme de classification, entra√Æn√© sur la base totale des images d√©crite en page 14 et de m√©ta-donn√©es pouvant y √™tre rattach√©es (telles que le niveau de bleu dans l‚Äôimage qui est un premier pr√©dicteur du caract√®re malade ou non de la plante) et test√© sur une base constitu√©e de 20% des images concern√©es avec un objectif d‚Äôaccuracy de 95% des feuilles malades.  B√¢tir une application

Dans le dataframe des images de bonnes qualit√©s, il y a 79 599 images, dont les trois premi√®res esp√®ces repr√©sentent + 45% du total.  Distribution des esp√®ces dans le dataframe ‚Äúlow quality‚Äù  
   Il y a 47 069 images, on peut remarquer que l‚Äôensemble des images des esp√®ces cassave, riz, et sucre de canne ne sont pr√©sentes que sur le dataframe de mauvaise qualit√©.  Mesure d‚Äôam√©lioration de la qualit√© des images  Distribution du flou avant/apr√®s retraitements 
 D'apr√®s la visualisation, la densit√©

Principe     ‚Ä¢ Les classes minoritaires (Healthy, Bacterial blight, Brown streak disease, Green mottle) ont √©t√© massivement augment√©es.     ‚Ä¢ L‚Äôobjectif √©tait d‚Äôatteindre un volume comparable √† la classe majoritaire (Cassava Mosaic Disease).     ‚Ä¢ Les techniques utilis√©es incluent : rotations, flips, changements de luminosit√©, contrastes, translations, etc. Objectifs     ‚Ä¢ Apporter de la diversit√© visuelle aux classes sous-repr√©sent√©es.     ‚Ä¢ R√©duire le biais induit par la classe majoritaire.   

que les images sont devenues plus nettes et moins floues apr√®s avoir subi les ajustements sur la nettet√©.  Analyse du contraste et de la luminosit√© avant et apr√®s retraitement 
 Les bo√Ætes √† moustaches montrent que le retraitement a am√©lior√© la qualit√© des images en r√©duisant les valeurs aberrantes. Pour le contraste, la m√©diane est rest√©e stable, mais les valeurs tr√®s faibles de contraste ont √©t√© corrig√©es, et la gamme des valeurs s'est √©largie. De m√™me, pour la luminosit√©, la m√©diane est incha

5. Redimensionnement de l‚Äôimage La fonction `resize_image(image, width, height)` redimensionne les images √† une taille sp√©cifi√©e (ici, 256x256 pixels). Cette op√©ration est r√©alis√©e avec la m√©thode `resize()` de PIL en utilisant l'algorithme `LANCZOS`, qui permet de pr√©server la qualit√© de l'image lors du redimensionnement.  6. Configuration des param√®tres globaux Les facteurs de traitement sont d√©finis avant le traitement : ‚óè `brightness_factor` : Ajuste la luminosit√© (ici fix√© √† 0.8 pour une l√©

‚óè Fichier d‚Äôimages de feuilles d‚Äôarbres fruitiers, de l√©gumineuses et de c√©r√©ales, malades ou saines ‚óè Dataset d‚Äôentra√Ænement de 43.456 images ‚óè Dataset de test de 10.849 images ‚óè Volum√©tries restreintes aux images d‚Äôesp√®ces v√©g√©tales : 100%  https://www.kaggle.com/abdallahalidev/plantvillage-dataset ‚óè Fichier d‚Äôimages de feuilles d‚Äôarbres fruitiers, de l√©gumineuses et de c√©r√©ales, malades ou saines ‚óè 3 Datasets de 54305 images chacun avec les m√™mes images en couleur, niveau de gris et pr√©trait√©

================================================================================

[2025-08-10 22:03:31,340] INFO - üîç Re-ranking des 24 chunks pour : ¬´ R√©sume la pipeline d'entra√Ænement ¬ª
### Question
R√©sume la pipeline d'entra√Ænement

**Top‚ÄëK**: 8

### Top K chunks (rerank cos_sim)
- **#1** | score=0.8289 | id=`9713ff1e-78b1-46d5-bd65-f7059f4c5231` | len=1440
  
> Optimisation  Nos mod√®les ont √©t√© optimis√©s en suivant 2 phases.   Phase 1  La premi√®re phase a repos√© sur :  ‚óè des corrections d‚Äôerreur : mesures de pr√©cision sur des images test et non les images d‚Äôentra√Ænement ; ‚óè des ‚Äú√©lagages‚Äù rapides de mod√®les jug√©s non pertinents ; ‚óè l‚Äôutilisation de techniques de fine-tuning : choix des ‚Äúoptimizers‚Äù, gel/d√©gel de couches des mod√®les po‚Ä¶

- **#2** | score=0.8128 | id=`0995f76b-c954-4aad-b8f1-d0f2d9099856` | len=1956
  
> ‚óè Augmentation cibl√©e : Techniques d'augmentation sp√©cialis√©es par type de maladie (GANs, style transfer) ‚óè Donn√©es multi-modales : Int√©gration d'informations contextuelles (g√©olocalisation, saison, ‚Ä¶) Optimisations architecturales ‚óè Mod√®les hybrides : Combinaison CNN-RNN avec r√©seaux Liquid Time-Constant pour traitement temporel ‚óè Attention mechanisms : Int√©gration de m√©canism‚Ä¶

- **#3** | score=0.8146 | id=`72b71cc8-1b49-41c4-a07a-02d429ac58d0` | len=1191
  
> S‚Äôagissant des autres classes, on rel√®ve les principaux enseignements suivants: ‚óè Raisins, cerises, agrumes, pommes, p√™ches, etc. (classes √©quilibr√©es) : les trois mod√®les ont des scores F1 proches de 1.00 sur toutes ces classes : aucune distinction significative. ‚óè Sugarcane (classes mineures) : Bonne performance des trois mod√®les. EfficientNetV2M excellent suivi de ViT16 ‚óè To‚Ä¶

- **#4** | score=0.8131 | id=`867088fa-9a44-426f-b62d-753121ec7317` | len=1630
  
> Autres ‚óè Incompatibilit√©s techniques : Probl√®mes de compatibilit√© entre TensorFlow 2.19 et certains outils d'interpr√©tation (SHAP DeepExplainer, GradCam) ‚óè Migration entre frameworks : Passage de FastAI vers TensorFlow pour faciliter l'int√©gration Firebase, n√©cessitant la r√©-impl√©mentation de certains mod√®les Bilan Contribution principale dans l'atteinte des objectifs Notre con‚Ä¶

- **#5** | score=0.8079 | id=`b0ad325f-5dce-42e9-8656-275a0e3004cd` | len=1859
  
> Choix du mod√®le et optimisation  Algorithmes test√©s Nous avons retenu 6 algorithmes : ‚óè 3 algorithmes Keras avec les mod√®les ResNet50V2, EfficientNetB0 et EfficientNetV2M; ‚óè 1 algorithme FastAI avec le mod√®le efficientnet_b0 ‚óè 2 algorithmes Torch, l‚Äôun avec transfer learning (MobileNetV2, adapt√© pour une application mobile comme c‚Äôest l‚Äôobjectif ici) et l‚Äôautre sans transfer le‚Ä¶

- **#6** | score=0.8080 | id=`ac912d76-42bb-4258-b9c5-cc5c615c52ff` | len=896
  
> Niveaux d‚Äôexpertise  Niveaux d‚Äôexpertise interne  Nom Algorithmie D√©v. Appli mobile Statistiques Gestion projet Botanique  Ela CIMEN 2/5 0/5 3/5 4/5 3/5 Roland KONAN 4/5 2/5 3/5 4/5 2/5 Yacine MADI SAID 3/5 5/5 2/5 4/5 1/5 Nicolas RINC√â 2/5 0/5 4/5 4/5 1/5  Recours √† expertise externe  Nous n‚Äôavons pas eu recours √† des experts externes √† proprement parler (en-dehors de Damien √©‚Ä¶

- **#7** | score=0.8097 | id=`3d173df0-266c-4374-a322-403282b97f75` | len=1574
  
> Les m√©triques pr√©cision, recall et F1-score gagnent environ 1pt pour atteindre 95% et 98% pour respectivement EfficientNetB0 et VGG12. Ce dernier est donc plus performant, ce qui √©limine le premier mod√®le. Bien que dans l‚Äôapprentissage de ces deux mod√®les, les classes ‚ÄúCassava‚Äù aient √©t√© exclues, on note des classes de tomates moins bien pr√©dites telles que celles atteintes des‚Ä¶

- **#8** | score=0.8157 | id=`0852c901-df96-450b-b583-1532c8b3e4bc` | len=1449
  
> Troisi√®me Entra√Ænement (Am√©lioration 2) AdamW CosineDecayRestarts SparseFocalLoss (avec poids des classes) earlystop, time_callback, printLR, model_checkpoint_callback  20 epochs max de finetuning Augmentation manuelle des images des classes minoritaires sur Cassava + augmentation cibl√©e sur ces classes  La troisi√®me √©tape s‚Äôest av√©r√©e la plus significative en mati√®re de gain d‚Ä¶


---
### Contexte concat√©n√© (troncature √©ventuelle)

Optimisation  Nos mod√®les ont √©t√© optimis√©s en suivant 2 phases.   Phase 1  La premi√®re phase a repos√© sur :  ‚óè des corrections d‚Äôerreur : mesures de pr√©cision sur des images test et non les images d‚Äôentra√Ænement ; ‚óè des ‚Äú√©lagages‚Äù rapides de mod√®les jug√©s non pertinents ; ‚óè l‚Äôutilisation de techniques de fine-tuning : choix des ‚Äúoptimizers‚Äù, gel/d√©gel de couches des mod√®les pour l‚Äôapprentissage, technique d‚Äôaugmentation de data, ajustement des learning rates et introduction de scheduler, modifi

‚óè Augmentation cibl√©e : Techniques d'augmentation sp√©cialis√©es par type de maladie (GANs, style transfer) ‚óè Donn√©es multi-modales : Int√©gration d'informations contextuelles (g√©olocalisation, saison, ‚Ä¶) Optimisations architecturales ‚óè Mod√®les hybrides : Combinaison CNN-RNN avec r√©seaux Liquid Time-Constant pour traitement temporel ‚óè Attention mechanisms : Int√©gration de m√©canismes d'attention pour focaliser sur les zones pathologiques ‚óè Architecture adaptative : Mod√®les capables d'ajuster leur co

S‚Äôagissant des autres classes, on rel√®ve les principaux enseignements suivants: ‚óè Raisins, cerises, agrumes, pommes, p√™ches, etc. (classes √©quilibr√©es) : les trois mod√®les ont des scores F1 proches de 1.00 sur toutes ces classes : aucune distinction significative. ‚óè Sugarcane (classes mineures) : Bonne performance des trois mod√®les. EfficientNetV2M excellent suivi de ViT16 ‚óè Tomato (13 sous-classes, tr√®s repr√©sent√© mais vari√©) : Bonne performance des trois mod√®les. EfficientNetV2M excellent suiv

Autres ‚óè Incompatibilit√©s techniques : Probl√®mes de compatibilit√© entre TensorFlow 2.19 et certains outils d'interpr√©tation (SHAP DeepExplainer, GradCam) ‚óè Migration entre frameworks : Passage de FastAI vers TensorFlow pour faciliter l'int√©gration Firebase, n√©cessitant la r√©-impl√©mentation de certains mod√®les Bilan Contribution principale dans l'atteinte des objectifs Notre contribution principale r√©side dans le d√©veloppement d'une pipeline compl√®te de traitement et de classification d'images de

Choix du mod√®le et optimisation  Algorithmes test√©s Nous avons retenu 6 algorithmes : ‚óè 3 algorithmes Keras avec les mod√®les ResNet50V2, EfficientNetB0 et EfficientNetV2M; ‚óè 1 algorithme FastAI avec le mod√®le efficientnet_b0 ‚óè 2 algorithmes Torch, l‚Äôun avec transfer learning (MobileNetV2, adapt√© pour une application mobile comme c‚Äôest l‚Äôobjectif ici) et l‚Äôautre sans transfer learning ‚óè 1 algorithme AlexNet  R√©sultats par mod√®le  1- KERAS  Keras est une biblioth√®que open-source de haut niveau pou

Niveaux d‚Äôexpertise  Niveaux d‚Äôexpertise interne  Nom Algorithmie D√©v. Appli mobile Statistiques Gestion projet Botanique 
Ela CIMEN 2/5 0/5 3/5 4/5 3/5 Roland KONAN 4/5 2/5 3/5 4/5 2/5 Yacine MADI SAID 3/5 5/5 2/5 4/5 1/5 Nicolas RINC√â 2/5 0/5 4/5 4/5 1/5  Recours √† expertise externe  Nous n‚Äôavons pas eu recours √† des experts externes √† proprement parler (en-dehors de Damien √©videmment !) mais avons r√©alis√© de nombreuses recherches afin de nous guider, notamment sur les sujets suivants : ‚óè Tail

Les m√©triques pr√©cision, recall et F1-score gagnent environ 1pt pour atteindre 95% et 98% pour respectivement EfficientNetB0 et VGG12. Ce dernier est donc plus performant, ce qui √©limine le premier mod√®le. Bien que dans l‚Äôapprentissage de ces deux mod√®les, les classes ‚ÄúCassava‚Äù aient √©t√© exclues, on note des classes de tomates moins bien pr√©dites telles que celles atteintes des maladies ‚ÄúMosaic Virus‚Äù et ‚ÄúSpider Mites‚Äù (Pr√©cision : 73%, Recall : 98%, F1-Score : 84%). On note d‚Äôailleurs qu‚Äô√† l‚Äôoe

Troisi√®me Entra√Ænement (Am√©lioration 2) AdamW CosineDecayRestarts SparseFocalLoss (avec poids des classes) earlystop, time_callback, printLR, model_checkpoint_callback 
20 epochs max de finetuning Augmentation manuelle des images des classes minoritaires sur Cassava + augmentation cibl√©e sur ces classes  La troisi√®me √©tape s‚Äôest av√©r√©e la plus significative en mati√®re de gain de performance, avec un traitement sp√©cifique apport√©e √† la classe ‚ÄúCassava‚Äù  en augmentant manuellement les images des c

================================================================================

[2025-08-10 22:04:21,293] INFO - üîç Re-ranking des 24 chunks pour : ¬´ Quelles sont les m√©triques finales ? ¬ª
### Question
Quelles sont les m√©triques finales ?

**Top‚ÄëK**: 6

### Top K chunks (rerank cos_sim)
- **#1** | score=0.8149 | id=`e0b6462a-689d-4b99-b578-cfa902e77c2d` | len=1678
  
> Conclusions pr√©-mod√©lisation   Nous disposons au terme de cette √©tape d‚Äôun fichier homog√®ne en termes de qualit√© d‚Äôimages, d‚Äôune quantit√© a priori suffisante pour appliquer un algorithme de reconnaissance, au d√©s√©quilibre entre classes moins marqu√© que sur les donn√©es d‚Äôorigine, et qui affiche d√©j√† quelques variables discriminantes sur l‚Äôune des deux variables cibles. Partie 4 ‚Ä¶

- **#2** | score=0.8071 | id=`2c2f34d4-b9ea-4151-9068-cee564e32ed4` | len=439
  
> M√©triques secondaires  Loss : Nous avons √©galement jaug√© la rapidit√© de la convergence du mod√®le en suivant la notion de loss √† chaque √©poque de l‚Äôapprentissage.   Selon les mod√®les et afin de nous assurer, malgr√© le faible d√©s√©quilibre de classes, que les classes les moins repr√©sent√©es soient correctement trait√©es, nous avons observ√© dans certains cas quelle √©tait la k-√®me Acc‚Ä¶

- **#3** | score=0.8025 | id=`3d173df0-266c-4374-a322-403282b97f75` | len=1574
  
> Les m√©triques pr√©cision, recall et F1-score gagnent environ 1pt pour atteindre 95% et 98% pour respectivement EfficientNetB0 et VGG12. Ce dernier est donc plus performant, ce qui √©limine le premier mod√®le. Bien que dans l‚Äôapprentissage de ces deux mod√®les, les classes ‚ÄúCassava‚Äù aient √©t√© exclues, on note des classes de tomates moins bien pr√©dites telles que celles atteintes des‚Ä¶

- **#4** | score=0.7998 | id=`912e7e83-d138-47d1-bced-fbe5860450cc` | len=2894
  
> M√©triques de performance utilis√©es pour comparer les mod√®les ............................................... 18 M√©trique principale ................................................................................................................................ 18 M√©triques secondaires ..............................................................................................‚Ä¶

- **#5** | score=0.7906 | id=`94d21018-bb40-43f2-94a7-4445fcd02dfc` | len=1955
  
> AlexNet est int√©ressant pour la classification d'images car il a introduit une architecture de r√©seau de neurones convolutifs profonds, utilisant des couches convolutives et des unit√©s de rectification lin√©aire (ReLU), qui a significativement am√©lior√© la pr√©cision de la reconnaissance d'images sur des jeux de donn√©es complexes comme ImageNet. Le mod√®le a √©t√© initialis√© en suiva‚Ä¶

- **#6** | score=0.7854 | id=`2e3849da-708d-40ed-a310-d537547ddeff` | len=1065
  
> ‚Ä¢ Optimisation pour le d√©ploiement mobile : Apprentissage des techniques de compression et quantification de mod√®les pour l'usage sur smartphone Pertinence ‚óè Choix architecturaux : N√©cessit√© de r√©viser l'approche initiale face aux performances insuffisantes sur certaines classes, menant √† l'exploration de mod√®les alternatifs (SwinTransformer) ou l‚Äôutilisation de certaines image‚Ä¶


---
### Contexte concat√©n√© (troncature √©ventuelle)

Conclusions pr√©-mod√©lisation   Nous disposons au terme de cette √©tape d‚Äôun fichier homog√®ne en termes de qualit√© d‚Äôimages, d‚Äôune quantit√© a priori suffisante pour appliquer un algorithme de reconnaissance, au d√©s√©quilibre entre classes moins marqu√© que sur les donn√©es d‚Äôorigine, et qui affiche d√©j√† quelques variables discriminantes sur l‚Äôune des deux variables cibles. Partie 4 : Mod√©lisation  Classification du probl√®me  Type de probl√®me de machine learning  La cible du projet est d‚Äôoffrir √† un i

M√©triques secondaires  Loss : Nous avons √©galement jaug√© la rapidit√© de la convergence du mod√®le en suivant la notion de loss √† chaque √©poque de l‚Äôapprentissage.   Selon les mod√®les et afin de nous assurer, malgr√© le faible d√©s√©quilibre de classes, que les classes les moins repr√©sent√©es soient correctement trait√©es, nous avons observ√© dans certains cas quelle √©tait la k-√®me Accuracy la plus faible parmi les classes propos√©es au mod√®le.

Les m√©triques pr√©cision, recall et F1-score gagnent environ 1pt pour atteindre 95% et 98% pour respectivement EfficientNetB0 et VGG12. Ce dernier est donc plus performant, ce qui √©limine le premier mod√®le. Bien que dans l‚Äôapprentissage de ces deux mod√®les, les classes ‚ÄúCassava‚Äù aient √©t√© exclues, on note des classes de tomates moins bien pr√©dites telles que celles atteintes des maladies ‚ÄúMosaic Virus‚Äù et ‚ÄúSpider Mites‚Äù (Pr√©cision : 73%, Recall : 98%, F1-Score : 84%). On note d‚Äôailleurs qu‚Äô√† l‚Äôoe

M√©triques de performance utilis√©es pour comparer les mod√®les ............................................... 18 M√©trique principale ................................................................................................................................ 18 M√©triques secondaires ........................................................................................................................... 18 Choix du mod√®le et optimisation .......................................................

AlexNet est int√©ressant pour la classification d'images car il a introduit une architecture de r√©seau de neurones convolutifs profonds, utilisant des couches convolutives et des unit√©s de rectification lin√©aire (ReLU), qui a significativement am√©lior√© la pr√©cision de la reconnaissance d'images sur des jeux de donn√©es complexes comme ImageNet. Le mod√®le a √©t√© initialis√© en suivant l‚Äôarchitecture suivante :  ‚óè Couches convolutives et pooling : L'architecture commence par deux couches convolutives 

‚Ä¢ Optimisation pour le d√©ploiement mobile : Apprentissage des techniques de compression et quantification de mod√®les pour l'usage sur smartphone Pertinence ‚óè Choix architecturaux : N√©cessit√© de r√©viser l'approche initiale face aux performances insuffisantes sur certaines classes, menant √† l'exploration de mod√®les alternatifs (SwinTransformer) ou l‚Äôutilisation de certaines images pr√©-retraitement (Cassave) ‚óè M√©triques d'√©valuation : Remise en question de l'accuracy comme m√©trique principale face 

================================================================================
