import os
import pickle
import faiss
import numpy as np
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex
from llama_index.core.node_parser import SentenceSplitter
from llama_index.vector_stores.faiss import FaissVectorStore
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# Param√®tres
DOCS_DIR = "data"
VECTOR_DIR = "vectordb"
INDEX_FILE = os.path.join(VECTOR_DIR, "index.faiss")
CHUNKS_FILE = os.path.join(VECTOR_DIR, "chunks.pkl")
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

os.makedirs(VECTOR_DIR, exist_ok=True)

# √âtape 1 ‚Äî Lecture
print("üì• Chargement des documents...")
documents = SimpleDirectoryReader(input_dir=DOCS_DIR).load_data()

# √âtape 2 ‚Äî Chunking avec overlap (512 tokens, 64 d'overlap)
print("‚úÇÔ∏è D√©coupage structur√© avec overlap...")

parser = SentenceSplitter(
    chunk_size=512,
    chunk_overlap=64,
    break_on_newlines=True  # üëà Important ici
)
#parser = SentenceSplitter(chunk_size=512, chunk_overlap=64)
nodes = parser.get_nodes_from_documents(documents)

# √âtape 3 ‚Äî Embedding + FAISS
print("üî¢ G√©n√©ration des embeddings et indexation FAISS...")
embed_model = HuggingFaceEmbedding(model_name=EMBEDDING_MODEL)

# Cr√©er un index brut FAISS
#dimension = embed_model.get_query_embedding("test").shape[0]
embedding_dim = np.array(embed_model.get_query_embedding("test")).shape[0]
faiss_index = faiss.IndexFlatL2(embedding_dim)
vector_store = FaissVectorStore(faiss_index=faiss_index)

# Cr√©ation de l‚Äôindex LlamaIndex avec FAISS
index = VectorStoreIndex(nodes, embed_model=embed_model, vector_store=vector_store)

# √âtape 4 ‚Äî Sauvegarde
print("üíæ Sauvegarde de l‚Äôindex et des chunks...")
#vector_store.save(INDEX_FILE)
faiss.write_index(faiss_index, INDEX_FILE)
chunks = [node.get_content() for node in nodes]
with open(CHUNKS_FILE, "wb") as f:
    pickle.dump(chunks, f)

print(f"‚úÖ {len(chunks)} chunks sauvegard√©s dans {CHUNKS_FILE}")
