{"question": "Est-ce que ce qui est mis en valeur est le fond noir ou le contour de la plante ?", "answer": "Le traitement SHAP indique que ce qui est mis en valeur dans l'image est le contour de la plante, non le fond noir.", "context": "Sur la classe 'Corn_Healthy', on peut avoir un doute sur l'angle gauche de l'image qui est coloré : Est-ce que ce qui est mis en valeur est le fond noir ou le contour de la plante ? Cette surbrillance n'étant pas mise en valeur sur le coin bas à gauche, je pense qu'il s'agit bien du contour de la plante, permettant sa reconnaissance. La colonne SHAP contient la classe pour laquelle l'image contient le plus de caractéristiques. Il confirme que notre modèle est capable de capturer les motifs et les éléments visuels pertinents pour effectuer des prédictions précises, étant donné qu'il s'agit à chaque fois de la bonne classe d'image sauf pour la classe 49 (Mosaic Virus). En analysant les graphiques sur cette classe, on confirme que le modèle a du mal à tirer ses caractéristiques spécifiques avec la classe 46.\n\nPlusieurs traitements sont appliqués aux images dans le but d'améliorer leur qualité. Les traitements incluent des ajustements sur la luminosité, le contraste, la netteté (flou et netteté), ainsi que des redimensionnements. Les étapes sont détaillées ci-dessous :\n\nDans certaines images, des zones d'attention sont visibles en dehors des feuilles, notamment sur l'arrière-plan ou sur d'autres objets. Cela suggère que le modèle peut être distrait par des éléments non pertinents.\n\n- Non exploité car bases de données non spécifiquement axées sur les plantes, de volumétrie limitée sur cette dernière catégorie, sans discrimination entre plantes saines et plantes malades, dont le seul intérêt était la présence de masques qui ne serviront pas dans les algorithmes choisis.\n\n- Conseil agricole : Outil d'aide au diagnostic pour conseillers et techniciens agricoles - Formation : Support pédagogique pour l'apprentissage de la reconnaissance des maladies - Certification : Contrôle qualité automatisé pour les filières agricoles\n\nL'application sera développée sur Streamlit conformément au schéma de l'application présentée en Page 6 en veillant à des règles d'ergonomie de « base » (éviter les images de fond, contraste des couleurs pour faciliter la lecture, usage des couleurs limité à une gamme réduite, boutons de navigation explicites, etc.) Jalons du projet\n\nLocaliser et classifier la maladie éventuelle touchant la plante dans cette même image La photographie retraitée, ou la photographie d'origine subissant de nouveaux filtres, sera soumise à un second algorithme de classification, entraîné sur la base totale des images décrite en page 14 et de méta-données pouvant y être rattachées (telles que le niveau de bleu dans l'image qui est un premier prédicteur du caractère malade ou non de la plante) et testé sur une base constituée de 20% des images concernées avec un objectif d'accuracy de 95% des feuilles malades. Bâtir une application renvoyant les informations de ces classifications à l'utilisateur sur la base d'une photographie prise sur son smartphone.\n\nLa fonction `calculate_blurriness(image)` utilise la méthode du Laplacien pour calculer le flou d'une image. Le flou est mesuré par la variance de la matrice du Laplacien sur l'image en niveaux de gris. Une faible variance indique un flou plus élevé, tandis qu'une haute variance indique une image plus nette."}
{"question": "Quels modèles ont été testés dans le projet ?", "answer": "Dans ce projet, les modèles principaux testés incluent :\n\n1. Un modèle simple sans Transfer Learning utilisant CNN.\n2. Des modèles pré-entraînés (non spécifiquement cités mais impliqués dans le comparatif).\n3. Un modèle AlexNet.\n4. Le SwinTransformer.\n\nLes autres modèles inclus à cet égard sont les Soft Voting et Stacking, ainsi que l'expérimentation avec différents filtrages, relabellisations et augmentations de données.", "context": "- Choix architecturaux : Nécessité de réviser l'approche initiale face aux performances insuffisantes sur certaines classes, menant à l'exploration de modèles alternatifs (SwinTransformer) ou l'utilisation de certaines images pré-retraitement (Cassave) - Métriques d'évaluation : Remise en question de l'accuracy comme métrique principale face au déséquilibre des classes et utilisation du F1-score - Stratégie de données : Questionnement sur l'inclusion/exclusion de la classe Cassave dans le modèle final - Puissance computationnelle : Temps d'entraînement prohibitifs pour certains modèles (EfficientNetV2M, VGG16) nécessitant l'optimisation du code et la réduction de la taille des images - Mémoire : Contraintes mémoire lors de l'entraînement de modèles profonds avec des images haute résolution - Déploiement : Défis de compression des modèles pour un usage mobile tout en préservant les performances\n\nNous avons exploré deux approches principales pour combiner les modèles : Soft Voting (vote pondéré par les probabilités) : chaque modèle contribue à la prédiction finale via sa distribution de probabilité. Nous avons initialement utilisé une pondération équivalente pour chaque modèle. Une étude systématique des coefficients de pondération n'a pas mis en évidence de combinaison significativement meilleure que l'équipondération. Cette méthode s'est avérée simple, stable, et a permis d'obtenir des résultats compétitifs. Stacking : cette approche consistait à utiliser un méta-modèle entraîné à partir des sorties des modèles de base.\n\nSelon les modèles et afin de nous assurer, malgré le faible déséquilibre de classes, que les classes les moins représentées soient correctement traitées, nous avons observé dans certains cas quelle était la k-ème Accuracy la plus faible parmi les classes proposées au modèle.\n\nL'application sera développée sur Streamlit conformément au schéma de l'application présentée en Page 6 en veillant à des règles d'ergonomie de « base » (éviter les images de fond, contraste des couleurs pour faciliter la lecture, usage des couleurs limité à une gamme réduite, boutons de navigation explicites, etc.) Jalons du projet\n\n- 1 modèle simple sans Transfer Learning, comprenant une première couche de convolution analysant le couleurs RGB (3 canaux) avec 32 filtres détectant les motifs simples et les contours, un deuxième bloc convolutif avec 64 filtres permettant de capter des motifs plus complexes (formes des feuilles, textures), une couche dense interprétant les motifs détectés et enfin la dernière couche de sortie donnant les probabilités par classe de plantes. La représentation du modèle est portée en Annexes. - Les 2 modèles ont été testés successivement sur 18 classes (espèces) et 58 classes (croisements espèces x maladies)\n\nLa deuxième phase a été consacrée à l'interprétation des modèles en utilisant des outils comme GradCam ou SHAP ainsi qu'à l'apprentissage, par lequel nous commençons cette phase, d'un modèle alternatif aux CNN et Transformer Standard : Swintransformer.\n\nLes résultats suivants comparent les performances des modèles avant et après application des trois stratégies (filtrage, relabellisation, augmentation) sur l'ensemble des classes (global) et spécifiquement sur les classes Cassava.\n\n- Le modèle entraîné sous Pytorch sans transfer learning, en raison de son taux de précision sur les images tests de 83%, très inférieur aux modèles pré-entraînés testés dans le chapitre précédent. - Le modèle AlexNet, qui affiche à la fois un temps d'entraînement trop important et un taux de précision de 88%, également très en-deça des autres modèles testés."}
{"question": "Quelles métriques principales et secondaires ont été utilisées ?", "answer": "Les métriques principales utilisées pour comparer les modèles sont l'Accuracy, définie comme le rapport entre le nombre de bonnes prédictions et le nombre total de prédictions. Les métriques secondaires utilisées sont la Loss, suivant la notion de loss à chaque époque de l'apprentissage.", "context": "La tâche associée est la reconnaissance d'images , spécifiquement de feuilles associées à 18 espèces végétales (fruits, légumineuses, céréales), dont les contours puis les détails sont progressivement analysées à travers les couches du réseau de neurones modélisé. Métriques de performance utilisées pour comparer les modèles A ce stade nous avons choisi 2 métriques. Métrique principale Accuracy : Compte tenu de la limitation du déséquilibre entre classes obtenu après la phase de pre-processing, nous avons choisi de retenir l'Accuracy comme métrique principale, définie comme le rapport entre le nombre de bonnes prédictions et le nombre total de prédictions. Métriques secondaires Loss : Nous avons également jaugé la rapidité de la convergence du modèle en suivant la notion de loss à chaque époque de l'apprentissage.\n\nPlusieurs traitements sont appliqués aux images dans le but d'améliorer leur qualité. Les traitements incluent des ajustements sur la luminosité, le contraste, la netteté (flou et netteté), ainsi que des redimensionnements. Les étapes sont détaillées ci-dessous :\n\n- Les classes minoritaires (Healthy, Bacterial blight, Brown streak disease, Green mottle) ont été massivement augmentées. - L'objectif était d'atteindre un volume comparable à la classe majoritaire (Cassava Mosaic Disease). - Les techniques utilisées incluent : rotations, flips, changements de luminosité, contrastes, translations, etc.\n\nL'application sera développée sur Streamlit conformément au schéma de l'application présentée en Page 6 en veillant à des règles d'ergonomie de « base » (éviter les images de fond, contraste des couleurs pour faciliter la lecture, usage des couleurs limité à une gamme réduite, boutons de navigation explicites, etc.) Jalons du projet\n\nLa deuxième phase a été consacrée à l'interprétation des modèles en utilisant des outils comme GradCam ou SHAP ainsi qu'à l'apprentissage, par lequel nous commençons cette phase, d'un modèle alternatif aux CNN et Transformer Standard : Swintransformer.\n\nNous n'avons pas eu recours à des experts externes à proprement parler (en-dehors de Damien évidemment !) mais avons réalisé de nombreuses recherches afin de nous guider, notamment sur les sujets suivants : - Taille des images standard utilisée dans les algorithmes de reconnaissance d'image ; - Détermination du niveau de flou d'une image et seuil d'acceptabilité pour la reconnaissance d'images (150 de Laplacienne) ; - Retraitement des niveaux de flous ; - Déséquilibre acceptable entre classes sur le fichier d'entraînement (1 à 10) ; Nombre minimal d'images à soumettre à l'algorithme par classe (1.000).\n\n, Résultats Global rank = . , models = EffNetV2M Swin. , accuracy = 0.9865. , fl score = 0.9856. , nb_models = . , cassava_only = False. , Résultats Global rank = . , models = EffNetV2M ResNet5oV2. , accuracy = 0.9855. , fl score = 0.9847. , nb_models = . , cassava_only = False. , Résultats Global rank = . , models = EffNetV2M. , accuracy = 0.9858. , fl score = 0.9845. , nb_models = . , cassava_only = False. , Résultats Global rank = . , models = EffNetV2M. , accuracy = 0.9841. , fl score = 0.9837. , nb_models = . , cassava_only = False. , Résultats Global rank = . , models = EffNetV2M Swin. , accuracy = 9851. , fl score = 9834. , nb_models = . , cassava_only = False. , Résultats\n\nWidth Width Avant retraitement, les images avaient des dimensions très variées, ce qui compliquait leur analyse et leur traitement uniforme. Cette hétérogénéité des tailles pouvait entraîner des biais lors de l'application de modèles d'apprentissage automatique ou d'autres analyses d'images, car les réseaux de neurones et les algorithmes de traitement d'images nécessitent des entrées de taille uniforme. Après retraitement, toutes les images ont été redimensionnées à une taille standard de 256x256 pixels, un format couramment utilisé dans la datascience. Cette normalisation permet non seulement de faciliter l'analyse et l'entraînement des modèles, mais elle garantit également que toutes les images sont traitées de manière cohérente, améliorant ainsi la performance des modèles d'analyse et de classification."}
