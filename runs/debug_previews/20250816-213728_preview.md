### Question
Comment les cartes de saillance ont-elles aidé l'interprétation des modèles ?

**Mode décidé**: `rag`   |   **Top‑K**: 10

### Top K chunks
- **#1** | score=0.8641 | id=`bdf58845-bf36-433b-9742-7a9101274b33` | len=742
  
> Pour comprendre les décisions de notre modèle VGG16, nous allons utiliser 3 outils d'interprétation : - -Saliency, qui permet de mettre en évidence les pixels les plus importants d'une image pour une prédiction donnée. - -SHAP (SHapley Additive exPlanations), pour visualiser les caractéristiques qui permettent la prédictions d'une classe sur une image. - -LIME (Local Interpreta…

- **#2** | score=0.8338 | id=`e0278322-9748-4ce7-b9b7-4c2688bf5d2c` | len=653
  
> L'ensemblage de modèles n'est pertinent que si les modèles présentent une certaine diversité d'erreurs. Pour cela, nous avons étudié : - -La corrélation des erreurs de classification entre les modèles. Des erreurs faiblement corrélées indiquent une complémentarité exploitable. - -La divergence de Jensen-Shannon entre les distributions de probabilité prédites. Une divergence mod…

- **#3** | score=0.8338 | id=`56acaba3-52e4-4e6d-80ff-a4355b76532e` | len=214
  
> - Exploiter les datasets nettoyés et enrichis. - Adapter les modèles à une distribution de données plus fiable. - Mesurer directement l'impact des stratégies sur les performances, notamment sur les classes Cassava.

- **#4** | score=0.8323 | id=`226afbc8-76b3-44ec-a4d0-9bda9a1781d3` | len=275
  
> Selon les modèles et afin de nous assurer, malgré le faible déséquilibre de classes, que les classes les moins représentées soient correctement traitées, nous avons observé dans certains cas quelle était la k-ème Accuracy la plus faible parmi les classes proposées au modèle.

- **#5** | score=0.8311 | id=`90781c83-7b22-4367-8531-123e3931b996` | len=680
  
> - ∞ Temps de préprocessing sous-estimé : Le nettoyage et l'homogénéisation des multiples datasets (fusion de bases redondantes, correction des déséquilibres entre classes) ont nécessité significativement plus de temps que prévu - ∞ Complexité du fine-tuning : Les itérations successives d'optimisation des modèles, particulièrement pour traiter les classes minoritaires comme la C…

- **#6** | score=0.8271 | id=`fde38fb3-f3b1-4e60-a261-d25bfb42653b` | len=422
  
> Le graphique ci-contre montre l'importance des variables dans la contribution à la classification et confirme en contributeur principal le niveau de bleu. Le taux de bonne prédiction de la classe malade est de 93,5% mais le modèle ne fonctionne pas correctement pour le classement des images saines (taux de prédiction de 74%) Un premier modèle Random Forest ent pour le classemen…

- **#7** | score=0.8260 | id=`a8c9a432-c50e-4512-870f-868079f1cb04` | len=316
  
> - Modèles hybrides : Combinaison CNN-RNN avec réseaux Liquid Time-Constant pour traitement temporel - Attention mechanisms : Intégration de mécanismes d'attention pour focaliser sur les zones pathologiques - Architecture adaptative : Modèles capables d'ajuster leur complexité selon la puissance de calcul disponible

- **#8** | score=0.8259 | id=`8b11b2d4-8af4-4f3e-a030-788ff073d347` | len=819
  
> Dans cette partie, nous étudions l'impact potentiel de l'ensemblage de modèles sur l'amélioration des performances de classification. Avant d'examiner les méthodes d'ensemblage, il est important de rappeler les performances des modèles pris individuellement dans leur configuration de base (sans stratégie d'amélioration) : - -EfficientNetV2M est le modèle ayant obtenu les meille…

- **#9** | score=0.8256 | id=`ba4702e4-ece1-4ee2-815f-cb09ebdb074a` | len=795
  
> Afin d'interpréter les modèles, nous avons utilisé GradCam pour visualiser les régions de l'image ayant le plus influencé la prédiction du modèle sur la base du dernier bloc du modèle. Pour une image de vigne atteinte de 'Black Measles' Image originale MobileNetV2 GradCAM Pour une image de Cassave saine (environnement végétal) Image originale MobileNetV2 GradCAM Pour une deuxiè…

- **#10** | score=0.8253 | id=`187b8190-ad51-4374-9983-86c3c0509a44` | len=615
  
> - 1 modèle simple sans Transfer Learning, comprenant une première couche de convolution analysant le couleurs RGB (3 canaux) avec 32 filtres détectant les motifs simples et les contours, un deuxième bloc convolutif avec 64 filtres permettant de capter des motifs plus complexes (formes des feuilles, textures), une couche dense interprétant les motifs détectés et enfin la dernièr…


---
### Contexte concaténé (troncature éventuelle)

Pour comprendre les décisions de notre modèle VGG16, nous allons utiliser 3 outils d'interprétation : - -Saliency, qui permet de mettre en évidence les pixels les plus importants d'une image pour une prédiction donnée. - -SHAP (SHapley Additive exPlanations), pour visualiser les caractéristiques qui permettent la prédictions d'une classe sur une image. - -LIME (Local Interpretable Model-agnostic Explanations), qui donne les caractéristiques d'une image qui vont le plus influencer la décision du 

L'ensemblage de modèles n'est pertinent que si les modèles présentent une certaine diversité d'erreurs. Pour cela, nous avons étudié : - -La corrélation des erreurs de classification entre les modèles. Des erreurs faiblement corrélées indiquent une complémentarité exploitable. - -La divergence de Jensen-Shannon entre les distributions de probabilité prédites. Une divergence modérée à forte entre modèles indique une diversité de décisions, facteur clé pour améliorer les résultats via l'agrégation

- Exploiter les datasets nettoyés et enrichis. - Adapter les modèles à une distribution de données plus fiable. - Mesurer directement l'impact des stratégies sur les performances, notamment sur les classes Cassava.

Selon les modèles et afin de nous assurer, malgré le faible déséquilibre de classes, que les classes les moins représentées soient correctement traitées, nous avons observé dans certains cas quelle était la k-ème Accuracy la plus faible parmi les classes proposées au modèle.

- ∞ Temps de préprocessing sous-estimé : Le nettoyage et l'homogénéisation des multiples datasets (fusion de bases redondantes, correction des déséquilibres entre classes) ont nécessité significativement plus de temps que prévu - ∞ Complexité du fine-tuning : Les itérations successives d'optimisation des modèles, particulièrement pour traiter les classes minoritaires comme la Cassave, ont multiplié les cycles de développement par 3 - ∞ Phase d'interprétation des modèles : L'utilisation d'outils 

Le graphique ci-contre montre l'importance des variables dans la contribution à la classification et confirme en contributeur principal le niveau de bleu. Le taux de bonne prédiction de la classe malade est de 93,5% mais le modèle ne fonctionne pas correctement pour le classement des images saines (taux de prédiction de 74%) Un premier modèle Random Forest ent pour le classement des images saines (taux de prédiction de

- Modèles hybrides : Combinaison CNN-RNN avec réseaux Liquid Time-Constant pour traitement temporel - Attention mechanisms : Intégration de mécanismes d'attention pour focaliser sur les zones pathologiques - Architecture adaptative : Modèles capables d'ajuster leur complexité selon la puissance de calcul disponible

Dans cette partie, nous étudions l'impact potentiel de l'ensemblage de modèles sur l'amélioration des performances de classification. Avant d'examiner les méthodes d'ensemblage, il est important de rappeler les performances des modèles pris individuellement dans leur configuration de base (sans stratégie d'amélioration) : - -EfficientNetV2M est le modèle ayant obtenu les meilleurs résultats globaux et sur Cassava. - -Swin Transformer a montré de bonnes performances, notamment une meilleure robus

Afin d'interpréter les modèles, nous avons utilisé GradCam pour visualiser les régions de l'image ayant le plus influencé la prédiction du modèle sur la base du dernier bloc du modèle. Pour une image de vigne atteinte de 'Black Measles' Image originale MobileNetV2 GradCAM Pour une image de Cassave saine (environnement végétal) Image originale MobileNetV2 GradCAM Pour une deuxième image de Cassave (environnement terre) Image originale MobileNetV2 GradCAM Swin Transformer Grad-CAM Sur un modèle CN

- 1 modèle simple sans Transfer Learning, comprenant une première couche de convolution analysant le couleurs RGB (3 canaux) avec 32 filtres détectant les motifs simples et les contours, un deuxième bloc convolutif avec 64 filtres permettant de capter des motifs plus complexes (formes des feuilles, textures), une couche dense interprétant les motifs détectés et enfin la dernière couche de sortie donnant les probabilités par classe de plantes. La représentation du modèle est portée en Annexes. - 