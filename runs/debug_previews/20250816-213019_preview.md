### Question
Quelles sont les conclusions sur l'inclusion de la classe Cassava dans le modèle final ?

**Mode décidé**: `rag`   |   **Top‑K**: 8

### Top K chunks
- **#1** | score=0.8669 | id=`797b1444-3c83-4dea-8d3a-80dad95e867f` | len=230
  
> Les résultats suivants comparent les performances des modèles avant et après application des trois stratégies (filtrage, relabellisation, augmentation) sur l'ensemble des classes (global) et spécifiquement sur les classes Cassava.

- **#2** | score=0.8636 | id=`f28357ab-c2b3-4cae-95b5-371f01b6f7ef` | len=621
  
> - Nous retenons le modèle ayant obtenu la meilleure performance sur le jeu de validation (les images du jeu de test). Dans les faits, nous avons eu besoin de 6 époques pour atteindre l'optimum avec un taux d'accuracy de 97,72%, un macro F1-score de 96,63% et un weighted F1-score de 97,73%. La classe Cassave reste néanmoins encore très moyennement prédite, rejoignant ainsi la co…

- **#3** | score=0.8608 | id=`0ed3e913-04c0-4973-985a-8a3e857d06c3` | len=343
  
> - Apporter de la diversité visuelle aux classes sous-représentées. - Réduire le biais induit par la classe majoritaire. - Améliorer la généralisation du modèle sur les classes rares. 2. Filtrage basé sur un score multi-critères Une seconde approche a consisté à filtrer les images Cassava jugées peu fiables à l'aide d'un score multi-critères.

- **#4** | score=0.8604 | id=`a5a7c73d-94ed-41f1-8fd7-0d469eb68387` | len=684
  
> - La qualité de la précision semble souffrir de la classe Cassave : quel que soit le modèle employé, et malgré les efforts de fine-tuning, il semble qu'une difficulté de reconnaissance subsiste pour cette classe. Cette difficulté est selon intrinsèquement lié à la qualité des images et aux problèmes apparents de labellisation. Nous nous interrogeons donc sur l'abandon de cette …

- **#5** | score=0.8603 | id=`a71a0380-0ab5-4170-a354-d0b93e69dfb6` | len=341
  
> Au vu des performances modestes obtenues par nos modèles sur le sous-ensemble Cassava, nous avons décidé de mettre en œuvre plusieurs stratégies d'amélioration. Ces approches visent à renforcer la qualité des données et à améliorer la capacité des modèles à discriminer les classes Cassava, souvent déséquilibrées et visuellement similaires.

- **#6** | score=0.8591 | id=`3bb8483a-8c45-476f-bf4b-00be772f1a0c` | len=371
  
> Compte tenu du faible % de prédiction, la Cassave a fait l'objet d'un focus particulier. On constate que le finetuning réalisé a eu un effet spectaculaire sur la reconnaissance de ces classes (hausse du F1-score de 15pts environ chez EfficientNetV2M et ViT16) notamment sur la Cassave saine. S'agissant des autres classes, on relève les principaux enseignements suivants:

- **#7** | score=0.8587 | id=`c4b45f53-7ecb-4be4-af0b-a6afad0c3bf8` | len=282
  
> On constate une baisse de l'Accuracy de 75,02% à 70,02% au terme du fine-tuning. La classification s'améliore sur l'ensemble des classes sauf sur la Tomate, la Cassave et la Canne à sucre. La faible Accuracy et la longueur de l'entraînement nous font conclure à l'abandon du modèle.

- **#8** | score=0.8584 | id=`ca40d432-be1f-4781-b3c2-f6e17d4e4386` | len=906
  
> - Choix architecturaux : Nécessité de réviser l'approche initiale face aux performances insuffisantes sur certaines classes, menant à l'exploration de modèles alternatifs (SwinTransformer) ou l'utilisation de certaines images pré-retraitement (Cassave) - Métriques d'évaluation : Remise en question de l'accuracy comme métrique principale face au déséquilibre des classes et utili…


---
### Contexte concaténé (troncature éventuelle)

Les résultats suivants comparent les performances des modèles avant et après application des trois stratégies (filtrage, relabellisation, augmentation) sur l'ensemble des classes (global) et spécifiquement sur les classes Cassava.

- Nous retenons le modèle ayant obtenu la meilleure performance sur le jeu de validation (les images du jeu de test). Dans les faits, nous avons eu besoin de 6 époques pour atteindre l'optimum avec un taux d'accuracy de 97,72%, un macro F1-score de 96,63% et un weighted F1-score de 97,73%. La classe Cassave reste néanmoins encore très moyennement prédite, rejoignant ainsi la conclusion générale que les images qui servent à l'apprentissage pour ces classes sont sans doute à l'origine de ce problè

- Apporter de la diversité visuelle aux classes sous-représentées. - Réduire le biais induit par la classe majoritaire. - Améliorer la généralisation du modèle sur les classes rares. 2. Filtrage basé sur un score multi-critères Une seconde approche a consisté à filtrer les images Cassava jugées peu fiables à l'aide d'un score multi-critères.

- La qualité de la précision semble souffrir de la classe Cassave : quel que soit le modèle employé, et malgré les efforts de fine-tuning, il semble qu'une difficulté de reconnaissance subsiste pour cette classe. Cette difficulté est selon intrinsèquement lié à la qualité des images et aux problèmes apparents de labellisation. Nous nous interrogeons donc sur l'abandon de cette classe dans le modèle final. - Les modèles affichent des tailles variables, certains sans doute incompatibles avec un us

Au vu des performances modestes obtenues par nos modèles sur le sous-ensemble Cassava, nous avons décidé de mettre en œuvre plusieurs stratégies d'amélioration. Ces approches visent à renforcer la qualité des données et à améliorer la capacité des modèles à discriminer les classes Cassava, souvent déséquilibrées et visuellement similaires.

Compte tenu du faible % de prédiction, la Cassave a fait l'objet d'un focus particulier. On constate que le finetuning réalisé a eu un effet spectaculaire sur la reconnaissance de ces classes (hausse du F1-score de 15pts environ chez EfficientNetV2M et ViT16) notamment sur la Cassave saine. S'agissant des autres classes, on relève les principaux enseignements suivants:

On constate une baisse de l'Accuracy de 75,02% à 70,02% au terme du fine-tuning. La classification s'améliore sur l'ensemble des classes sauf sur la Tomate, la Cassave et la Canne à sucre. La faible Accuracy et la longueur de l'entraînement nous font conclure à l'abandon du modèle.

- Choix architecturaux : Nécessité de réviser l'approche initiale face aux performances insuffisantes sur certaines classes, menant à l'exploration de modèles alternatifs (SwinTransformer) ou l'utilisation de certaines images pré-retraitement (Cassave) - Métriques d'évaluation : Remise en question de l'accuracy comme métrique principale face au déséquilibre des classes et utilisation du F1-score - Stratégie de données : Questionnement sur l'inclusion/exclusion de la classe Cassave dans le modèle